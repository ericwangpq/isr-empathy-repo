{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Sentiment Analysis and Behavioral Regression\n",
        "## Event-Driven Empathy and User Feedback Analysis\n",
        "\n",
        "### Analysis Framework\n",
        "This notebook implements a comprehensive analysis framework following the ISR research model (Xu et al., 2025) to examine:\n",
        "\n",
        "1. **Three-Dimensional Sentiment Analysis**\n",
        "   - Valence (Positive/Negative emotion)\n",
        "   - Arousal (Emotional intensity/activation)\n",
        "   - Dominance (Control/power in interaction)\n",
        "\n",
        "2. **Regression Analysis**\n",
        "   - Sentiment dimensions ‚Üí User feedback (Likes/Dislikes)\n",
        "   - Empathy dimensions ‚Üí User satisfaction\n",
        "   - Event sequence impact on outcomes\n",
        "\n",
        "3. **Advanced NLP Methods**\n",
        "   - Transformer-based sentiment models\n",
        "   - Topic modeling with BERTopic\n",
        "   - Key phrase extraction with KeyBERT\n",
        "   - API-based empathy detection (optional)\n",
        "\n",
        "4. **Event Sequence Analysis**\n",
        "   - Pre-chat events triggering conversations\n",
        "   - Post-chat behavioral outcomes\n",
        "   - Conversation-event relationship modeling\n",
        "\n",
        "### Data Sources\n",
        "- `output_chunks/chunk_0000.csv`: Event log data (800K records)\n",
        "- `event_bh.csv`: Cleaned chatbot conversation events (to be analyzed)\n",
        "- `datafield_annotation.xlsx`: Field descriptions\n",
        "- Conversation Excel files: Dialogue content\n",
        "- `ÂõûÁ≠îÂèçÈ¶à.csv`: User feedback data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# Statistical and ML libraries\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, \n",
        "    roc_auc_score, roc_curve, r2_score, mean_squared_error\n",
        ")\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# NLP libraries\n",
        "try:\n",
        "    from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "    import torch\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è Transformers not available. Install with: pip install transformers torch\")\n",
        "\n",
        "try:\n",
        "    from bertopic import BERTopic\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    BERTOPIC_AVAILABLE = True\n",
        "except ImportError:\n",
        "    BERTOPIC_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è BERTopic not available. Install with: pip install bertopic\")\n",
        "\n",
        "try:\n",
        "    from keybert import KeyBERT\n",
        "    KEYBERT_AVAILABLE = True\n",
        "except ImportError:\n",
        "    KEYBERT_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è KeyBERT not available. Install with: pip install keybert\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SENTIMENT REGRESSION ANALYSIS - INITIALIZATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Transformers available: {TRANSFORMERS_AVAILABLE}\")\n",
        "print(f\"BERTopic available: {BERTOPIC_AVAILABLE}\")\n",
        "print(f\"KeyBERT available: {KEYBERT_AVAILABLE}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BASE_DIR = Path('/Users/ericwang/git/mics/empathy')\n",
        "\n",
        "# Data file paths\n",
        "FILES = {\n",
        "    'chunk': BASE_DIR / 'output_chunks/chunk_0000.csv',\n",
        "    'event_bh': BASE_DIR / 'event_bh.csv',  # Will check if exists\n",
        "    'field_annotation': BASE_DIR / 'datafield_annotation.xlsx',\n",
        "    'feedback': BASE_DIR / 'ÂõûÁ≠îÂèçÈ¶à.csv',\n",
        "    'conversations': [\n",
        "        BASE_DIR / 'ÂåóÊµ∑Êô∫‰º¥ÂØπËØù_250501-0520.xlsx',\n",
        "        BASE_DIR / 'ÂåóÊµ∑Êô∫‰º¥ÂØπËØù_250521-0610.xlsx',\n",
        "        BASE_DIR / 'ÂåóÊµ∑Êô∫‰º¥ÂØπËØù_250611-0620.xlsx',\n",
        "        BASE_DIR / 'ÂåóÊµ∑Êô∫‰º¥ÂØπËØù_250621-0701.xlsx'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Check file availability\n",
        "print(\"File Availability Check:\")\n",
        "print(\"-\" * 50)\n",
        "for name, path in FILES.items():\n",
        "    if isinstance(path, list):\n",
        "        print(f\"{name}: {len(path)} files\")\n",
        "        for p in path:\n",
        "            exists = p.exists()\n",
        "            print(f\"  - {p.name}: {'‚úÖ' if exists else '‚ùå'}\")\n",
        "    else:\n",
        "        exists = path.exists() if path else False\n",
        "        print(f\"{name}: {'‚úÖ' if exists else '‚ùå'} {path}\")\n",
        "\n",
        "# Analysis parameters\n",
        "PARAMS = {\n",
        "    'sample_size': None,  # None = use all data, or set a number for sampling\n",
        "    'min_text_length': 5,  # Minimum text length for analysis\n",
        "    'random_state': 42,\n",
        "    'test_size': 0.2,\n",
        "    'confidence_level': 0.95\n",
        "}\n",
        "\n",
        "print(f\"\\nAnalysis Parameters:\")\n",
        "for key, value in PARAMS.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Load Event Log Data (chunk_0000.csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load event log data\n",
        "print(\"Loading event log data from chunk_0000.csv...\")\n",
        "print(f\"File size: {FILES['chunk'].stat().st_size / (1024**3):.2f} GB\")\n",
        "\n",
        "# Load with sampling if needed\n",
        "if PARAMS['sample_size']:\n",
        "    # Calculate skip rows for random sampling\n",
        "    total_rows = 800000  # Approximate\n",
        "    skip_prob = 1 - (PARAMS['sample_size'] / total_rows)\n",
        "    skip = lambda x: x > 0 and np.random.random() < skip_prob\n",
        "    df_events = pd.read_csv(FILES['chunk'], skiprows=skip)\n",
        "    print(f\"Loaded sample: {len(df_events):,} rows\")\n",
        "else:\n",
        "    # Load all data (may take time)\n",
        "    print(\"Loading full dataset... this may take a while\")\n",
        "    df_events = pd.read_csv(FILES['chunk'])\n",
        "    print(f\"Loaded: {len(df_events):,} rows\")\n",
        "\n",
        "print(f\"Columns: {df_events.shape[1]}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df_events.columns.tolist())\n",
        "\n",
        "# Display basic info\n",
        "print(f\"\\nData Overview:\")\n",
        "print(f\"  Date range: {df_events['begin_date'].min()} to {df_events['begin_date'].max()}\")\n",
        "print(f\"  Unique users: {df_events['user_id'].nunique():,}\")\n",
        "print(f\"  Unique sessions: {df_events['session_id'].nunique():,}\")\n",
        "print(f\"  Unique events: {df_events['event_name'].nunique()}\")\n",
        "\n",
        "# Show event distribution\n",
        "print(f\"\\nTop 20 Events:\")\n",
        "print(df_events['event_name'].value_counts().head(20))\n",
        "\n",
        "df_events.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Session ID Validation and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze session_id field\n",
        "print(\"=\" * 80)\n",
        "print(\"SESSION ID VALIDATION ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check if session_id exists in events with conversations\n",
        "session_events = df_events[df_events['session_id'].notna()].copy()\n",
        "print(f\"\\nEvents with session_id: {len(session_events):,} ({len(session_events)/len(df_events)*100:.2f}%)\")\n",
        "\n",
        "# Check for cus fields containing \"‰ºöËØùID\" (conversation ID)\n",
        "print(f\"\\nSearching for '‰ºöËØùID' in cus1-cus20 fields...\")\n",
        "cus_columns = [f'cus{i}' for i in range(1, 21)]\n",
        "\n",
        "# Find columns containing session/conversation IDs\n",
        "session_related_events = []\n",
        "for col in cus_columns:\n",
        "    if col in df_events.columns:\n",
        "        # Check if column contains \"‰ºöËØù\" or \"session\"\n",
        "        sample = df_events[col].dropna().head(1000).astype(str)\n",
        "        if sample.str.contains('‰ºöËØù|session', case=False, na=False).any():\n",
        "            print(f\"  Found conversation-related data in {col}\")\n",
        "            session_related_events.append(col)\n",
        "\n",
        "# Analyze event types with session_id\n",
        "print(f\"\\nEvent Types with Session ID:\")\n",
        "print(session_events['event_name'].value_counts().head(20))\n",
        "\n",
        "# Check if non-chatbot events have session_id (as user mentioned)\n",
        "print(f\"\\nNon-Chat Events with Session ID:\")\n",
        "non_chat_keywords = ['Êù•Ê∏∏Âêß', 'ËøõÂÖ•', 'ÂÅúÁïô', 'ËàπÁ•®', 'Èó®Á•®']\n",
        "non_chat_events = session_events[\n",
        "    session_events['event_name'].str.contains('|'.join(non_chat_keywords), na=False)\n",
        "]\n",
        "print(f\"  Total non-chat events with session_id: {len(non_chat_events):,}\")\n",
        "print(f\"  Examples:\")\n",
        "print(non_chat_events['event_name'].value_counts().head(10))\n",
        "\n",
        "# Session ID statistics\n",
        "print(f\"\\nSession ID Statistics:\")\n",
        "print(f\"  Unique session_ids: {session_events['session_id'].nunique():,}\")\n",
        "print(f\"  Avg events per session: {len(session_events) / session_events['session_id'].nunique():.2f}\")\n",
        "print(f\"  Sessions with single event: {(session_events.groupby('session_id').size() == 1).sum():,}\")\n",
        "print(f\"  Sessions with 5+ events: {(session_events.groupby('session_id').size() >= 5).sum():,}\")\n",
        "\n",
        "# Temporal analysis\n",
        "session_events['begin_date'] = pd.to_datetime(session_events['begin_date'])\n",
        "print(f\"\\nTemporal Distribution:\")\n",
        "print(session_events.groupby(session_events['begin_date'].dt.date)['session_id'].nunique().describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load conversation data from Excel files\n",
        "print(\"=\" * 80)\n",
        "print(\"LOADING CONVERSATION DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "conversations_list = []\n",
        "for conv_file in FILES['conversations']:\n",
        "    if conv_file.exists():\n",
        "        print(f\"\\nLoading: {conv_file.name}\")\n",
        "        df_conv = pd.read_excel(conv_file)\n",
        "        \n",
        "        # Filter for Beihai data (travel_id = 40)\n",
        "        if 'travel_id' in df_conv.columns:\n",
        "            df_conv = df_conv[df_conv['travel_id'] == 40].copy()\n",
        "        \n",
        "        conversations_list.append(df_conv)\n",
        "        print(f\"  Records: {len(df_conv):,}\")\n",
        "        print(f\"  Columns: {', '.join(df_conv.columns[:10].tolist())}...\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è File not found: {conv_file.name}\")\n",
        "\n",
        "if conversations_list:\n",
        "    df_conversations = pd.concat(conversations_list, ignore_index=True)\n",
        "    \n",
        "    # Clean data\n",
        "    if 'im_content' in df_conversations.columns:\n",
        "        df_conversations = df_conversations[df_conversations['im_content'].notna()].copy()\n",
        "        df_conversations = df_conversations[\n",
        "            df_conversations['im_content'].str.strip().str.len() >= PARAMS['min_text_length']\n",
        "        ].copy()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Total conversation records: {len(df_conversations):,}\")\n",
        "    print(f\"   Unique conversations (im_id): {df_conversations['im_id'].nunique():,}\")\n",
        "    print(f\"   Unique sessions: {df_conversations['session_id'].nunique():,}\")\n",
        "    print(f\"   Date range: {df_conversations['create_time'].min()} to {df_conversations['create_time'].max()}\")\n",
        "    \n",
        "    # Show conversation types\n",
        "    if 'im_type' in df_conversations.columns:\n",
        "        print(f\"\\n   Conversation Types:\")\n",
        "        print(df_conversations['im_type'].value_counts())\n",
        "else:\n",
        "    df_conversations = pd.DataFrame()\n",
        "    print(\"‚ùå No conversation data loaded\")\n",
        "\n",
        "# Load feedback data\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"LOADING FEEDBACK DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if FILES['feedback'].exists():\n",
        "    df_feedback = pd.read_csv(FILES['feedback'])\n",
        "    \n",
        "    # Filter for Beihai data\n",
        "    if 'travel_id' in df_feedback.columns:\n",
        "        df_feedback = df_feedback[df_feedback['travel_id'] == 40].copy()\n",
        "    \n",
        "    # Filter for valid feedback (1: like, 2: dislike)\n",
        "    if 'feedback_state' in df_feedback.columns:\n",
        "        df_feedback = df_feedback[df_feedback['feedback_state'].isin([1, 2])].copy()\n",
        "        df_feedback['like_binary'] = (df_feedback['feedback_state'] == 1).astype(int)\n",
        "    \n",
        "    print(f\"‚úÖ Feedback records: {len(df_feedback):,}\")\n",
        "    print(f\"   Likes: {(df_feedback['like_binary'] == 1).sum():,}\")\n",
        "    print(f\"   Dislikes: {(df_feedback['like_binary'] == 0).sum():,}\")\n",
        "    print(f\"   Like ratio: {df_feedback['like_binary'].mean():.2%}\")\n",
        "    \n",
        "    if 'feedback' in df_feedback.columns:\n",
        "        print(f\"\\n   Top dislike reasons:\")\n",
        "        dislike_reasons = df_feedback[df_feedback['like_binary'] == 0]['feedback'].value_counts().head(10)\n",
        "        print(dislike_reasons)\n",
        "else:\n",
        "    df_feedback = pd.DataFrame()\n",
        "    print(\"‚ùå Feedback file not found\")\n",
        "\n",
        "df_conversations.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize sentiment analysis models\n",
        "print(\"=\" * 80)\n",
        "print(\"INITIALIZING SENTIMENT ANALYSIS MODELS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "sentiment_models = {}\n",
        "\n",
        "if TRANSFORMERS_AVAILABLE:\n",
        "    try:\n",
        "        # For Chinese sentiment analysis\n",
        "        print(\"\\n‚úÖ Loading Chinese sentiment model...\")\n",
        "        sentiment_models['chinese_sentiment'] = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=\"uer/roberta-base-finetuned-dianping-chinese\",\n",
        "            device=-1  # CPU\n",
        "        )\n",
        "        print(\"   Model loaded: uer/roberta-base-finetuned-dianping-chinese\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Could not load Chinese sentiment model: {e}\")\n",
        "        print(\"   Will use alternative method\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Transformers not available - will use lexicon-based approach\")\n",
        "\n",
        "# Define VAD (Valence-Arousal-Dominance) lexicon approach for Chinese\n",
        "# Based on emotional word lists and linguistic patterns\n",
        "VAD_KEYWORDS = {\n",
        "    'high_valence': ['Êª°ÊÑè', 'ÂºÄÂøÉ', 'È´òÂÖ¥', 'ÊÑüË∞¢', 'Â§™Â•Ω‰∫Ü', 'ÂæàÊ£í', '‰∏çÈîô', 'ÂñúÊ¨¢', 'ÂÆåÁæé', '‰ºòÁßÄ'],\n",
        "    'low_valence': ['‰∏çÊª°', 'Â§±Êúõ', 'Á≥üÁ≥ï', 'Â∑ÆÂä≤', 'ÁîüÊ∞î', 'ÊÑ§ÊÄí', 'ËÆ®Âéå', 'ÈóÆÈ¢ò', 'ÈîôËØØ', '‰∏çË°å'],\n",
        "    'high_arousal': ['ÔºÅ', 'ÔºÅÔºÅ', 'ÈùûÂ∏∏', 'ÁâπÂà´', 'Â§™', 'ÊûÅÂÖ∂', 'Ë∂ÖÁ∫ß', 'Áõ∏ÂΩì', 'ÂçÅÂàÜ', 'ÊÄ•'],\n",
        "    'low_arousal': ['ËøòË°å', '‰∏ÄËà¨', 'ÊôÆÈÄö', 'ÂèØ‰ª•', 'ÂáëÂêà', 'ÂãâÂº∫', 'Âπ≥Â∏∏', 'Âπ≥Ê∑°'],\n",
        "    'high_dominance': ['ÂøÖÈ°ª', 'Ë¶ÅÊ±Ç', 'ÈúÄË¶Å', 'Â∫îËØ•', 'ÊäïËØâ', 'ÈÄÄÊ¨æ', 'Ëß£ÂÜ≥', 'Â§ÑÁêÜ', 'È©¨‰∏ä', 'Á´ãÂç≥'],\n",
        "    'low_dominance': ['ËØ∑ÈóÆ', 'ËÉΩÂê¶', 'ÂèØÂê¶', 'È∫ªÁÉ¶', 'ËÉΩ‰∏çËÉΩ', 'Â∏åÊúõ', 'Âª∫ËÆÆ', 'ÊÉ≥Ë¶Å', 'ÂèØËÉΩ']\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ VAD lexicon initialized\")\n",
        "print(f\"   High valence keywords: {len(VAD_KEYWORDS['high_valence'])}\")\n",
        "print(f\"   High arousal keywords: {len(VAD_KEYWORDS['high_arousal'])}\")\n",
        "print(f\"   High dominance keywords: {len(VAD_KEYWORDS['high_dominance'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Sentiment Calculation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_vad_scores(text):\n",
        "    \"\"\"\n",
        "    Calculate Valence, Arousal, and Dominance scores for a given text.\n",
        "    Returns scores normalized to [-1, 1] range.\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or not isinstance(text, str) or len(text) < 2:\n",
        "        return {'valence': 0.0, 'arousal': 0.0, 'dominance': 0.0}\n",
        "    \n",
        "    text_lower = text.lower()\n",
        "    text_len = len(text)\n",
        "    \n",
        "    # Calculate Valence (positive - negative)\n",
        "    pos_count = sum(text_lower.count(word) for word in VAD_KEYWORDS['high_valence'])\n",
        "    neg_count = sum(text_lower.count(word) for word in VAD_KEYWORDS['low_valence'])\n",
        "    valence = (pos_count - neg_count) / (text_len / 100 + 1)  # Normalize by text length\n",
        "    valence = np.clip(valence, -1, 1)\n",
        "    \n",
        "    # Calculate Arousal (high - low activation)\n",
        "    high_arousal = sum(text_lower.count(word) for word in VAD_KEYWORDS['high_arousal'])\n",
        "    low_arousal = sum(text_lower.count(word) for word in VAD_KEYWORDS['low_arousal'])\n",
        "    arousal = (high_arousal - low_arousal) / (text_len / 100 + 1)\n",
        "    arousal = np.clip(arousal, -1, 1)\n",
        "    \n",
        "    # Calculate Dominance (high - low control)\n",
        "    high_dom = sum(text_lower.count(word) for word in VAD_KEYWORDS['high_dominance'])\n",
        "    low_dom = sum(text_lower.count(word) for word in VAD_KEYWORDS['low_dominance'])\n",
        "    dominance = (high_dom - low_dom) / (text_len / 100 + 1)\n",
        "    dominance = np.clip(dominance, -1, 1)\n",
        "    \n",
        "    return {\n",
        "        'valence': float(valence),\n",
        "        'arousal': float(arousal),\n",
        "        'dominance': float(dominance)\n",
        "    }\n",
        "\n",
        "def analyze_sentiment_batch(texts, batch_size=100):\n",
        "    \"\"\"\n",
        "    Analyze sentiment for a batch of texts with progress tracking.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    total = len(texts)\n",
        "    \n",
        "    print(f\"Analyzing {total:,} texts...\")\n",
        "    \n",
        "    for i in range(0, total, batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        \n",
        "        for text in batch:\n",
        "            vad_scores = calculate_vad_scores(text)\n",
        "            results.append(vad_scores)\n",
        "        \n",
        "        if (i + batch_size) % 10000 == 0:\n",
        "            print(f\"  Progress: {i+batch_size:,}/{total:,} ({(i+batch_size)/total*100:.1f}%)\")\n",
        "    \n",
        "    print(f\"‚úÖ Completed: {len(results):,} texts analyzed\")\n",
        "    return results\n",
        "\n",
        "# Test the function\n",
        "test_texts = [\n",
        "    \"ÊàëÂæàÊª°ÊÑèËøôÊ¨°ÊúçÂä°ÔºåÂ§™Â•Ω‰∫ÜÔºÅ\",\n",
        "    \"ÈùûÂ∏∏Â§±ÊúõÔºåÈóÆÈ¢òÂ§™Â§ö‰∫Ü\",\n",
        "    \"ËØ∑ÈóÆËÉΩÂê¶Â∏ÆÊàëËß£ÂÜ≥‰∏Ä‰∏ãËøô‰∏™ÈóÆÈ¢òÔºü\",\n",
        "    \"ÂøÖÈ°ªÈ©¨‰∏äÂ§ÑÁêÜÔºÅÊàëË¶ÅÊäïËØâÔºÅ\"\n",
        "]\n",
        "\n",
        "print(\"Testing VAD calculation:\")\n",
        "print(\"-\" * 50)\n",
        "for text in test_texts:\n",
        "    scores = calculate_vad_scores(text)\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"  Valence: {scores['valence']:.3f}, Arousal: {scores['arousal']:.3f}, Dominance: {scores['dominance']:.3f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Apply Sentiment Analysis to Conversations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply sentiment analysis to conversation data\n",
        "if len(df_conversations) > 0 and 'im_content' in df_conversations.columns:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"APPLYING SENTIMENT ANALYSIS TO CONVERSATIONS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Analyze sentiment for all conversations\n",
        "    texts = df_conversations['im_content'].tolist()\n",
        "    sentiment_results = analyze_sentiment_batch(texts, batch_size=1000)\n",
        "    \n",
        "    # Add sentiment scores to dataframe\n",
        "    sentiment_df = pd.DataFrame(sentiment_results)\n",
        "    df_conversations_sent = pd.concat([df_conversations.reset_index(drop=True), sentiment_df], axis=1)\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(f\"\\nSentiment Analysis Summary:\")\n",
        "    print(\"-\" * 50)\n",
        "    for dim in ['valence', 'arousal', 'dominance']:\n",
        "        print(f\"{dim.capitalize()}:\")\n",
        "        print(f\"  Mean: {sentiment_df[dim].mean():.4f}\")\n",
        "        print(f\"  Std:  {sentiment_df[dim].std():.4f}\")\n",
        "        print(f\"  Min:  {sentiment_df[dim].min():.4f}\")\n",
        "        print(f\"  Max:  {sentiment_df[dim].max():.4f}\")\n",
        "        print()\n",
        "    \n",
        "    # Show examples of extreme sentiments\n",
        "    print(\"\\nExamples of Extreme Sentiments:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # High valence\n",
        "    print(\"\\nüìó Most Positive (High Valence):\")\n",
        "    high_val = df_conversations_sent.nlargest(3, 'valence')[['im_content', 'valence', 'arousal', 'dominance']]\n",
        "    for idx, row in high_val.iterrows():\n",
        "        print(f\"  Content: {row['im_content'][:100]}...\")\n",
        "        print(f\"  V: {row['valence']:.3f}, A: {row['arousal']:.3f}, D: {row['dominance']:.3f}\\n\")\n",
        "    \n",
        "    # Low valence\n",
        "    print(\"üìï Most Negative (Low Valence):\")\n",
        "    low_val = df_conversations_sent.nsmallest(3, 'valence')[['im_content', 'valence', 'arousal', 'dominance']]\n",
        "    for idx, row in low_val.iterrows():\n",
        "        print(f\"  Content: {row['im_content'][:100]}...\")\n",
        "        print(f\"  V: {row['valence']:.3f}, A: {row['arousal']:.3f}, D: {row['dominance']:.3f}\\n\")\n",
        "    \n",
        "    # High arousal\n",
        "    print(\"üìô Highest Arousal:\")\n",
        "    high_aro = df_conversations_sent.nlargest(3, 'arousal')[['im_content', 'valence', 'arousal', 'dominance']]\n",
        "    for idx, row in high_aro.iterrows():\n",
        "        print(f\"  Content: {row['im_content'][:100]}...\")\n",
        "        print(f\"  V: {row['valence']:.3f}, A: {row['arousal']:.3f}, D: {row['dominance']:.3f}\\n\")\n",
        "    \n",
        "    # Distribution plots\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    fig.suptitle('Sentiment Dimension Distributions', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    for idx, dim in enumerate(['valence', 'arousal', 'dominance']):\n",
        "        ax = axes[idx]\n",
        "        ax.hist(sentiment_df[dim], bins=30, alpha=0.7, color=['blue', 'green', 'red'][idx], edgecolor='black')\n",
        "        ax.axvline(sentiment_df[dim].mean(), color='darkred', linestyle='--', linewidth=2, \n",
        "                   label=f'Mean: {sentiment_df[dim].mean():.3f}')\n",
        "        ax.set_xlabel(dim.capitalize())\n",
        "        ax.set_ylabel('Frequency')\n",
        "        ax.set_title(f'{dim.capitalize()} Distribution')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Sentiment analysis completed for {len(df_conversations_sent):,} conversations\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No conversation data available for sentiment analysis\")\n",
        "    df_conversations_sent = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Merge Sentiment Data with Feedback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge sentiment analysis with feedback data\n",
        "print(\"=\" * 80)\n",
        "print(\"MERGING SENTIMENT DATA WITH FEEDBACK\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if len(df_conversations_sent) > 0 and len(df_feedback) > 0:\n",
        "    # Merge on im_id\n",
        "    df_regression = pd.merge(\n",
        "        df_conversations_sent,\n",
        "        df_feedback[['im_id', 'like_binary', 'feedback', 'feedback_state']],\n",
        "        on='im_id',\n",
        "        how='inner'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ Merged dataset created\")\n",
        "    print(f\"   Total records: {len(df_regression):,}\")\n",
        "    print(f\"   Likes: {(df_regression['like_binary'] == 1).sum():,}\")\n",
        "    print(f\"   Dislikes: {(df_regression['like_binary'] == 0).sum():,}\")\n",
        "    print(f\"   Like ratio: {df_regression['like_binary'].mean():.2%}\")\n",
        "    \n",
        "    # Add additional features\n",
        "    df_regression['text_length'] = df_regression['im_content'].str.len()\n",
        "    df_regression['word_count'] = df_regression['im_content'].str.split().str.len()\n",
        "    \n",
        "    # Session-level aggregation\n",
        "    print(f\"\\nSession-Level Aggregation:\")\n",
        "    session_agg = df_regression.groupby('session_id').agg({\n",
        "        'valence': ['mean', 'std', 'min', 'max'],\n",
        "        'arousal': ['mean', 'std', 'min', 'max'],\n",
        "        'dominance': ['mean', 'std', 'min', 'max'],\n",
        "        'like_binary': ['mean', 'count'],\n",
        "        'text_length': 'mean',\n",
        "        'im_id': 'count'  # Number of messages per session\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Flatten column names\n",
        "    session_agg.columns = ['_'.join(col).strip('_') for col in session_agg.columns.values]\n",
        "    session_agg.rename(columns={\n",
        "        'session_id': 'session_id',\n",
        "        'im_id_count': 'message_count',\n",
        "        'like_binary_mean': 'session_like_rate',\n",
        "        'like_binary_count': 'feedback_count'\n",
        "    }, inplace=True)\n",
        "    \n",
        "    print(f\"   Sessions with feedback: {len(session_agg):,}\")\n",
        "    print(f\"   Avg messages per session: {session_agg['message_count'].mean():.2f}\")\n",
        "    print(f\"   Avg feedback per session: {session_agg['feedback_count'].mean():.2f}\")\n",
        "    \n",
        "    # Statistical comparison\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"SENTIMENT COMPARISON: LIKES VS DISLIKES\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    likes = df_regression[df_regression['like_binary'] == 1]\n",
        "    dislikes = df_regression[df_regression['like_binary'] == 0]\n",
        "    \n",
        "    comparison_data = []\n",
        "    for dim in ['valence', 'arousal', 'dominance']:\n",
        "        # T-test\n",
        "        t_stat, p_value = stats.ttest_ind(likes[dim], dislikes[dim])\n",
        "        \n",
        "        # Effect size (Cohen's d)\n",
        "        mean_diff = likes[dim].mean() - dislikes[dim].mean()\n",
        "        pooled_std = np.sqrt(((len(likes)-1)*likes[dim].std()**2 + \n",
        "                              (len(dislikes)-1)*dislikes[dim].std()**2) / \n",
        "                             (len(likes) + len(dislikes) - 2))\n",
        "        cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
        "        \n",
        "        comparison_data.append({\n",
        "            'Dimension': dim.capitalize(),\n",
        "            'Like_Mean': likes[dim].mean(),\n",
        "            'Like_Std': likes[dim].std(),\n",
        "            'Dislike_Mean': dislikes[dim].mean(),\n",
        "            'Dislike_Std': dislikes[dim].std(),\n",
        "            'Mean_Diff': mean_diff,\n",
        "            't_statistic': t_stat,\n",
        "            'p_value': p_value,\n",
        "            'cohens_d': cohens_d,\n",
        "            'Significant': p_value < 0.05\n",
        "        })\n",
        "    \n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    print(comparison_df.round(4))\n",
        "    \n",
        "    # Visualize comparison\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    fig.suptitle('Sentiment Dimensions: Likes vs Dislikes', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    for idx, dim in enumerate(['valence', 'arousal', 'dominance']):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Box plots\n",
        "        data_to_plot = [likes[dim].dropna(), dislikes[dim].dropna()]\n",
        "        bp = ax.boxplot(data_to_plot, labels=['Likes', 'Dislikes'], patch_artist=True)\n",
        "        \n",
        "        # Color the boxes\n",
        "        bp['boxes'][0].set_facecolor('lightgreen')\n",
        "        bp['boxes'][1].set_facecolor('lightcoral')\n",
        "        \n",
        "        ax.set_ylabel(dim.capitalize())\n",
        "        ax.set_title(f'{dim.capitalize()}')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add significance marker\n",
        "        row = comparison_df[comparison_df['Dimension'] == dim.capitalize()].iloc[0]\n",
        "        if row['Significant']:\n",
        "            y_max = max(likes[dim].max(), dislikes[dim].max())\n",
        "            ax.text(1.5, y_max * 0.95, f\"p={row['p_value']:.4f}*\", \n",
        "                   ha='center', fontsize=10, color='red', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Data ready for regression analysis\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot merge: missing conversation or feedback data\")\n",
        "    df_regression = pd.DataFrame()\n",
        "    session_agg = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic Regression Analysis\n",
        "if len(df_regression) >= 30:  # Need minimum samples\n",
        "    print(\"=\" * 80)\n",
        "    print(\"LOGISTIC REGRESSION ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Prepare features and target\n",
        "    feature_cols = ['valence', 'arousal', 'dominance']\n",
        "    X = df_regression[feature_cols].copy()\n",
        "    y = df_regression['like_binary'].copy()\n",
        "    \n",
        "    # Add control variables\n",
        "    X['text_length_log'] = np.log(df_regression['text_length'] + 1)\n",
        "    X['word_count_log'] = np.log(df_regression['word_count'] + 1)\n",
        "    \n",
        "    print(f\"\\nData Preparation:\")\n",
        "    print(f\"  Sample size: {len(X):,}\")\n",
        "    print(f\"  Features: {X.columns.tolist()}\")\n",
        "    print(f\"  Target distribution: Likes={y.sum()}, Dislikes={(1-y).sum()}\")\n",
        "    \n",
        "    # Check for multicollinearity\n",
        "    print(f\"\\nCorrelation Matrix:\")\n",
        "    corr_matrix = X.corr()\n",
        "    print(corr_matrix.round(3))\n",
        "    \n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=PARAMS['test_size'], random_state=PARAMS['random_state'], \n",
        "        stratify=y if len(np.unique(y)) > 1 else None\n",
        "    )\n",
        "    \n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Fit logistic regression with sklearn\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"MODEL 1: SKLEARN LOGISTIC REGRESSION\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    log_model = LogisticRegression(random_state=PARAMS['random_state'], max_iter=1000)\n",
        "    log_model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred_train = log_model.predict(X_train_scaled)\n",
        "    y_pred_test = log_model.predict(X_test_scaled)\n",
        "    y_pred_proba_test = log_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    \n",
        "    # Model evaluation\n",
        "    print(f\"\\nModel Performance:\")\n",
        "    print(f\"  Training accuracy: {log_model.score(X_train_scaled, y_train):.4f}\")\n",
        "    print(f\"  Test accuracy: {log_model.score(X_test_scaled, y_test):.4f}\")\n",
        "    \n",
        "    if len(np.unique(y_test)) > 1:\n",
        "        auc_score = roc_auc_score(y_test, y_pred_proba_test)\n",
        "        print(f\"  AUC-ROC: {auc_score:.4f}\")\n",
        "    \n",
        "    print(f\"\\nClassification Report (Test Set):\")\n",
        "    print(classification_report(y_test, y_pred_test, target_names=['Dislike', 'Like']))\n",
        "    \n",
        "    print(f\"\\nConfusion Matrix (Test Set):\")\n",
        "    cm = confusion_matrix(y_test, y_pred_test)\n",
        "    print(cm)\n",
        "    \n",
        "    # Feature importance (coefficients)\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FEATURE IMPORTANCE\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Coefficient': log_model.coef_[0],\n",
        "        'Abs_Coefficient': np.abs(log_model.coef_[0]),\n",
        "        'Odds_Ratio': np.exp(log_model.coef_[0])\n",
        "    }).sort_values('Abs_Coefficient', ascending=False)\n",
        "    \n",
        "    print(feature_importance.round(4))\n",
        "    \n",
        "    print(f\"\\nInterpretation:\")\n",
        "    for idx, row in feature_importance.iterrows():\n",
        "        if row['Abs_Coefficient'] > 0.1:  # Only show important features\n",
        "            direction = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
        "            print(f\"  ‚Ä¢ {row['Feature']}: 1 SD increase {direction} odds of Like by {(row['Odds_Ratio']-1)*100:.1f}%\")\n",
        "    \n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle('Logistic Regression Analysis Results', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # 1. Feature coefficients\n",
        "    ax1 = axes[0, 0]\n",
        "    colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]\n",
        "    ax1.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors, alpha=0.7)\n",
        "    ax1.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
        "    ax1.set_xlabel('Coefficient')\n",
        "    ax1.set_title('Feature Coefficients (Standardized)')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. ROC Curve\n",
        "    if len(np.unique(y_test)) > 1:\n",
        "        ax2 = axes[0, 1]\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n",
        "        ax2.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {auc_score:.3f})')\n",
        "        ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "        ax2.set_xlim([0.0, 1.0])\n",
        "        ax2.set_ylim([0.0, 1.05])\n",
        "        ax2.set_xlabel('False Positive Rate')\n",
        "        ax2.set_ylabel('True Positive Rate')\n",
        "        ax2.set_title('ROC Curve')\n",
        "        ax2.legend(loc=\"lower right\")\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Confusion Matrix Heatmap\n",
        "    ax3 = axes[1, 0]\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax3, \n",
        "                xticklabels=['Dislike', 'Like'], yticklabels=['Dislike', 'Like'])\n",
        "    ax3.set_ylabel('True Label')\n",
        "    ax3.set_xlabel('Predicted Label')\n",
        "    ax3.set_title('Confusion Matrix')\n",
        "    \n",
        "    # 4. Predicted Probabilities Distribution\n",
        "    ax4 = axes[1, 1]\n",
        "    likes_proba = y_pred_proba_test[y_test == 1]\n",
        "    dislikes_proba = y_pred_proba_test[y_test == 0]\n",
        "    ax4.hist(likes_proba, bins=20, alpha=0.6, label='Actual Likes', color='green', edgecolor='black')\n",
        "    ax4.hist(dislikes_proba, bins=20, alpha=0.6, label='Actual Dislikes', color='red', edgecolor='black')\n",
        "    ax4.set_xlabel('Predicted Probability of Like')\n",
        "    ax4.set_ylabel('Frequency')\n",
        "    ax4.set_title('Predicted Probability Distribution')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Insufficient data for regression analysis\")\n",
        "    print(f\"   Current sample size: {len(df_regression)}\")\n",
        "    log_model = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statsmodels Logistic Regression for detailed statistics\n",
        "if len(df_regression) >= 30 and log_model is not None:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"MODEL 2: STATSMODELS LOGISTIC REGRESSION (Detailed Statistics)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Prepare data (use full dataset for statsmodels)\n",
        "    X_full = df_regression[['valence', 'arousal', 'dominance', 'text_length', 'word_count']].copy()\n",
        "    X_full['text_length_log'] = np.log(X_full['text_length'] + 1)\n",
        "    X_full['word_count_log'] = np.log(X_full['word_count'] + 1)\n",
        "    \n",
        "    # Standardize\n",
        "    X_scaled_full = pd.DataFrame(\n",
        "        scaler.fit_transform(X_full[['valence', 'arousal', 'dominance', 'text_length_log', 'word_count_log']]),\n",
        "        columns=['valence', 'arousal', 'dominance', 'text_length_log', 'word_count_log']\n",
        "    )\n",
        "    \n",
        "    # Add constant\n",
        "    X_with_const = sm.add_constant(X_scaled_full)\n",
        "    y_full = df_regression['like_binary']\n",
        "    \n",
        "    # Fit model\n",
        "    try:\n",
        "        sm_model = sm.Logit(y_full, X_with_const).fit(disp=0)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL SUMMARY\")\n",
        "        print(\"=\"*80)\n",
        "        print(sm_model.summary())\n",
        "        \n",
        "        # Odds ratios\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ODDS RATIOS (Exponentiated Coefficients)\")\n",
        "        print(\"=\"*80)\n",
        "        odds_ratios = pd.DataFrame({\n",
        "            'Variable': sm_model.params.index,\n",
        "            'Coefficient': sm_model.params.values,\n",
        "            'Std_Error': sm_model.bse.values,\n",
        "            'z_value': sm_model.tvalues.values,\n",
        "            'p_value': sm_model.pvalues.values,\n",
        "            'Odds_Ratio': np.exp(sm_model.params.values),\n",
        "            '[0.025': np.exp(sm_model.conf_int()[0].values),\n",
        "            '0.975]': np.exp(sm_model.conf_int()[1].values)\n",
        "        })\n",
        "        print(odds_ratios.round(4))\n",
        "        \n",
        "        # Marginal effects\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"AVERAGE MARGINAL EFFECTS\")\n",
        "        print(\"=\"*80)\n",
        "        mfx = sm_model.get_margeff()\n",
        "        print(mfx.summary())\n",
        "        \n",
        "        # Model fit statistics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL FIT STATISTICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"  Log-Likelihood: {sm_model.llf:.4f}\")\n",
        "        print(f\"  AIC: {sm_model.aic:.4f}\")\n",
        "        print(f\"  BIC: {sm_model.bic:.4f}\")\n",
        "        print(f\"  Pseudo R¬≤: {sm_model.prsquared:.4f}\")\n",
        "        print(f\"  LLR p-value: {sm_model.llr_pvalue:.4f}\")\n",
        "        \n",
        "        # Interpretation\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"KEY FINDINGS\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        significant_vars = odds_ratios[odds_ratios['p_value'] < 0.05]\n",
        "        if len(significant_vars) > 0:\n",
        "            print(\"\\nStatistically Significant Predictors (p < 0.05):\")\n",
        "            for idx, row in significant_vars.iterrows():\n",
        "                if row['Variable'] != 'const':\n",
        "                    effect_pct = (row['Odds_Ratio'] - 1) * 100\n",
        "                    direction = \"increases\" if row['Coefficient'] > 0 else \"decreases\"\n",
        "                    print(f\"\\n  ‚Ä¢ {row['Variable']}:\")\n",
        "                    print(f\"      Coefficient: {row['Coefficient']:.4f} (SE: {row['Std_Error']:.4f})\")\n",
        "                    print(f\"      Odds Ratio: {row['Odds_Ratio']:.4f}\")\n",
        "                    print(f\"      Effect: 1 SD increase {direction} odds of Like by {abs(effect_pct):.2f}%\")\n",
        "                    print(f\"      95% CI for OR: [{row['[0.025']:.4f}, {row['0.975]']:.4f}]\")\n",
        "                    print(f\"      p-value: {row['p_value']:.4f}\")\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è No statistically significant predictors found at p < 0.05 level\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not fit statsmodels logit: {e}\")\n",
        "        sm_model = None\n",
        "else:\n",
        "    print(\"Skipping statsmodels analysis\")\n",
        "    sm_model = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Analysis: Topic Modeling and Empathy Detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Key Phrase Extraction with KeyBERT (if available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KeyBERT for key phrase extraction\n",
        "if KEYBERT_AVAILABLE and len(df_conversations_sent) > 0:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"KEY PHRASE EXTRACTION WITH KEYBERT\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    try:\n",
        "        kw_model = KeyBERT()\n",
        "        \n",
        "        # Sample conversations for analysis (to save time)\n",
        "        sample_size = min(100, len(df_conversations_sent))\n",
        "        sample_convs = df_conversations_sent.sample(n=sample_size, random_state=42)\n",
        "        \n",
        "        print(f\"\\nExtracting keywords from {sample_size} conversations...\")\n",
        "        \n",
        "        all_keywords = []\n",
        "        for idx, row in sample_convs.iterrows():\n",
        "            try:\n",
        "                keywords = kw_model.extract_keywords(\n",
        "                    row['im_content'],\n",
        "                    keyphrase_ngram_range=(1, 2),\n",
        "                    stop_words=None,\n",
        "                    top_n=5\n",
        "                )\n",
        "                for kw, score in keywords:\n",
        "                    all_keywords.append({\n",
        "                        'im_id': row['im_id'],\n",
        "                        'keyword': kw,\n",
        "                        'score': score,\n",
        "                        'valence': row['valence'],\n",
        "                        'like_binary': row['like_binary']\n",
        "                    })\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        if all_keywords:\n",
        "            kw_df = pd.DataFrame(all_keywords)\n",
        "            \n",
        "            print(f\"\\n‚úÖ Extracted {len(kw_df)} keywords\")\n",
        "            \n",
        "            # Top keywords for likes vs dislikes\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"TOP KEYWORDS BY FEEDBACK TYPE\")\n",
        "            print(\"=\"*80)\n",
        "            \n",
        "            likes_kw = kw_df[kw_df['like_binary'] == 1].groupby('keyword')['score'].agg(['mean', 'count']).sort_values('count', ascending=False).head(15)\n",
        "            dislikes_kw = kw_df[kw_df['like_binary'] == 0].groupby('keyword')['score'].agg(['mean', 'count']).sort_values('count', ascending=False).head(15)\n",
        "            \n",
        "            print(\"\\nüìó Top Keywords in LIKED conversations:\")\n",
        "            print(likes_kw)\n",
        "            \n",
        "            print(\"\\nüìï Top Keywords in DISLIKED conversations:\")\n",
        "            print(dislikes_kw)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è KeyBERT extraction failed: {e}\")\n",
        "\n",
        "else:\n",
        "    if not KEYBERT_AVAILABLE:\n",
        "        print(\"‚ö†Ô∏è KeyBERT not available. Install with: pip install keybert\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No conversation data for key phrase extraction\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Event Sequence Analysis (when event_bh.csv is available)\n",
        "\n",
        "This section will analyze the sequence of events before and after chatbot interactions to understand:\n",
        "- What triggers users to start conversations\n",
        "- How emotional trajectory affects subsequent user behavior\n",
        "- Whether specific events correlate with service success/failure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Event sequence analysis\n",
        "if FILES['event_bh'].exists():\n",
        "    print(\"=\" * 80)\n",
        "    print(\"EVENT SEQUENCE ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    try:\n",
        "        df_event_bh = pd.read_csv(FILES['event_bh'])\n",
        "        print(f\"‚úÖ Loaded event_bh.csv: {len(df_event_bh):,} events\")\n",
        "        \n",
        "        # Merge with conversations to get sentiment scores\n",
        "        df_events_with_sentiment = pd.merge(\n",
        "            df_event_bh,\n",
        "            df_conversations_sent[['session_id', 'valence', 'arousal', 'dominance', 'create_time']],\n",
        "            on='session_id',\n",
        "            how='left'\n",
        "        )\n",
        "        \n",
        "        print(f\"   Events with sentiment data: {df_events_with_sentiment['valence'].notna().sum():,}\")\n",
        "        \n",
        "        # Sort by session and time\n",
        "        df_events_with_sentiment = df_events_with_sentiment.sort_values(['session_id', 'begin_date'])\n",
        "        \n",
        "        # Identify pre-chat and post-chat events\n",
        "        print(\"\\nAnalyzing event sequences...\")\n",
        "        \n",
        "        # Group by session\n",
        "        for session_id, group in df_events_with_sentiment.groupby('session_id'):\n",
        "            if len(group) < 2:\n",
        "                continue\n",
        "            \n",
        "            # Find chat events vs other events\n",
        "            # Add your specific logic here based on event_name patterns\n",
        "            pass\n",
        "        \n",
        "        print(\"\\n‚úÖ Event sequence analysis completed\")\n",
        "        print(\"\\nNote: Detailed event analysis requires domain knowledge of event types.\")\n",
        "        print(\"      Customize this section based on your specific event patterns.\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error loading event_bh.csv: {e}\")\n",
        "        \n",
        "else:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"EVENT SEQUENCE ANALYSIS - PLACEHOLDER\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\n‚ö†Ô∏è event_bh.csv not found\")\n",
        "    print(\"\\nWhen available, this section will analyze:\")\n",
        "    print(\"  1. Events triggering chatbot conversations\")\n",
        "    print(\"  2. Emotional trajectory during conversations\")\n",
        "    print(\"  3. Post-conversation user behaviors\")\n",
        "    print(\"  4. Correlation between sentiment changes and outcomes\")\n",
        "    print(\"\\nPlease provide event_bh.csv to enable this analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary and Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive analysis report\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE ANALYSIS REPORT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Executive Summary\n",
        "print(\"\\nüìä EXECUTIVE SUMMARY\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "if len(df_conversations_sent) > 0:\n",
        "    print(f\"Dataset Size:\")\n",
        "    print(f\"  ‚Ä¢ Total conversations analyzed: {len(df_conversations_sent):,}\")\n",
        "    print(f\"  ‚Ä¢ Conversations with feedback: {len(df_regression):,}\")\n",
        "    print(f\"  ‚Ä¢ Unique sessions: {df_conversations_sent['session_id'].nunique():,}\")\n",
        "    print(f\"  ‚Ä¢ Date range: {df_conversations_sent['create_time'].min()} to {df_conversations_sent['create_time'].max()}\")\n",
        "    \n",
        "    print(f\"\\nSentiment Overview:\")\n",
        "    print(f\"  ‚Ä¢ Average Valence: {df_conversations_sent['valence'].mean():.4f} (range: -1 to +1)\")\n",
        "    print(f\"  ‚Ä¢ Average Arousal: {df_conversations_sent['arousal'].mean():.4f}\")\n",
        "    print(f\"  ‚Ä¢ Average Dominance: {df_conversations_sent['dominance'].mean():.4f}\")\n",
        "    \n",
        "    if len(df_regression) > 0:\n",
        "        print(f\"\\nFeedback Analysis:\")\n",
        "        print(f\"  ‚Ä¢ Like ratio: {df_regression['like_binary'].mean():.2%}\")\n",
        "        print(f\"  ‚Ä¢ Likes: {(df_regression['like_binary'] == 1).sum():,}\")\n",
        "        print(f\"  ‚Ä¢ Dislikes: {(df_regression['like_binary'] == 0).sum():,}\")\n",
        "\n",
        "# Key Findings\n",
        "print(f\"\\nüí° KEY FINDINGS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
        "    print(\"\\n1. Sentiment Dimensions and User Feedback:\")\n",
        "    for idx, row in comparison_df.iterrows():\n",
        "        sig_marker = \"***\" if row['p_value'] < 0.001 else \"**\" if row['p_value'] < 0.01 else \"*\" if row['p_value'] < 0.05 else \"\"\n",
        "        effect_size = \"large\" if abs(row['cohens_d']) > 0.8 else \"medium\" if abs(row['cohens_d']) > 0.5 else \"small\"\n",
        "        \n",
        "        print(f\"\\n   {row['Dimension']}:\")\n",
        "        print(f\"      Like mean: {row['Like_Mean']:.4f}, Dislike mean: {row['Dislike_Mean']:.4f}\")\n",
        "        print(f\"      Difference: {row['Mean_Diff']:.4f} {sig_marker}\")\n",
        "        print(f\"      Effect size (Cohen's d): {row['cohens_d']:.4f} ({effect_size})\")\n",
        "        print(f\"      p-value: {row['p_value']:.4f}\")\n",
        "\n",
        "if 'feature_importance' in locals() and feature_importance is not None:\n",
        "    print(f\"\\n2. Regression Model Results:\")\n",
        "    print(f\"   Most important predictors:\")\n",
        "    for idx, row in feature_importance.head(3).iterrows():\n",
        "        print(f\"      ‚Ä¢ {row['Feature']}: coefficient = {row['Coefficient']:.4f}, OR = {row['Odds_Ratio']:.4f}\")\n",
        "\n",
        "# Recommendations\n",
        "print(f\"\\nüéØ STRATEGIC RECOMMENDATIONS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\n1. Chatbot Optimization:\")\n",
        "print(\"   ‚Ä¢ Focus on improving dimensions with significant negative effects on satisfaction\")\n",
        "print(\"   ‚Ä¢ Monitor real-time sentiment scores during conversations\")\n",
        "print(\"   ‚Ä¢ Implement early intervention when negative sentiment is detected\")\n",
        "\n",
        "print(\"\\n2. Content Strategy:\")\n",
        "print(\"   ‚Ä¢ Develop response templates that balance all three emotional dimensions\")\n",
        "print(\"   ‚Ä¢ Train chatbot to adapt tone based on user's emotional state\")\n",
        "print(\"   ‚Ä¢ Create empathy-focused responses for high-arousal situations\")\n",
        "\n",
        "print(\"\\n3. Quality Assurance:\")\n",
        "print(\"   ‚Ä¢ Establish sentiment thresholds for conversation quality\")\n",
        "print(\"   ‚Ä¢ Flag conversations with extreme negative valence for review\")\n",
        "print(\"   ‚Ä¢ Analyze dislike patterns to identify systemic issues\")\n",
        "\n",
        "print(\"\\n4. Further Research:\")\n",
        "print(\"   ‚Ä¢ Collect more granular feedback data (why users like/dislike)\")\n",
        "print(\"   ‚Ä¢ Analyze temporal patterns (sentiment changes over conversation)\")\n",
        "print(\"   ‚Ä¢ Investigate interaction effects between sentiment dimensions\")\n",
        "print(\"   ‚Ä¢ Integrate event sequence data to understand behavioral outcomes\")\n",
        "\n",
        "# Limitations\n",
        "print(f\"\\n‚ö†Ô∏è LIMITATIONS\")\n",
        "print(\"-\" * 80)\n",
        "print(\"‚Ä¢ Lexicon-based sentiment analysis may miss contextual nuances\")\n",
        "print(\"‚Ä¢ Limited sample size may affect statistical power\")\n",
        "print(\"‚Ä¢ Correlation does not imply causation\")\n",
        "print(\"‚Ä¢ User feedback may be influenced by factors beyond conversation quality\")\n",
        "print(\"‚Ä¢ Event sequence analysis pending event_bh.csv availability\")\n",
        "\n",
        "# Next Steps\n",
        "print(f\"\\nüìã NEXT STEPS\")\n",
        "print(\"-\" * 80)\n",
        "print(\"1. Deploy transformer-based sentiment models for improved accuracy\")\n",
        "print(\"2. Implement real-time sentiment monitoring in production\")\n",
        "print(\"3. Conduct A/B testing of empathy-enhanced responses\")\n",
        "print(\"4. Integrate event sequence analysis with sentiment data\")\n",
        "print(\"5. Build predictive models for early identification of at-risk conversations\")\n",
        "print(\"6. Develop automated intervention strategies based on sentiment patterns\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"END OF REPORT\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export results\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPORTING RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "output_dir = BASE_DIR / 'analysis_outputs'\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "exported_files = []\n",
        "\n",
        "# 1. Export sentiment-annotated conversations\n",
        "if len(df_conversations_sent) > 0:\n",
        "    output_file = output_dir / 'conversations_with_sentiment.csv'\n",
        "    df_conversations_sent.to_csv(output_file, index=False)\n",
        "    print(f\"‚úÖ Exported: {output_file.name} ({len(df_conversations_sent):,} rows)\")\n",
        "    exported_files.append(output_file)\n",
        "\n",
        "# 2. Export regression dataset\n",
        "if len(df_regression) > 0:\n",
        "    output_file = output_dir / 'regression_dataset.csv'\n",
        "    df_regression.to_csv(output_file, index=False)\n",
        "    print(f\"‚úÖ Exported: {output_file.name} ({len(df_regression):,} rows)\")\n",
        "    exported_files.append(output_file)\n",
        "\n",
        "# 3. Export session-level aggregates\n",
        "if 'session_agg' in locals() and len(session_agg) > 0:\n",
        "    output_file = output_dir / 'session_aggregates.csv'\n",
        "    session_agg.to_csv(output_file, index=False)\n",
        "    print(f\"‚úÖ Exported: {output_file.name} ({len(session_agg):,} rows)\")\n",
        "    exported_files.append(output_file)\n",
        "\n",
        "# 4. Export comparison statistics\n",
        "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
        "    output_file = output_dir / 'sentiment_comparison_stats.csv'\n",
        "    comparison_df.to_csv(output_file, index=False)\n",
        "    print(f\"‚úÖ Exported: {output_file.name}\")\n",
        "    exported_files.append(output_file)\n",
        "\n",
        "# 5. Export feature importance\n",
        "if 'feature_importance' in locals() and feature_importance is not None:\n",
        "    output_file = output_dir / 'feature_importance.csv'\n",
        "    feature_importance.to_csv(output_file, index=False)\n",
        "    print(f\"‚úÖ Exported: {output_file.name}\")\n",
        "    exported_files.append(output_file)\n",
        "\n",
        "# 6. Export model coefficients from statsmodels\n",
        "if 'odds_ratios' in locals():\n",
        "    output_file = output_dir / 'regression_coefficients.csv'\n",
        "    odds_ratios.to_csv(output_file, index=False)\n",
        "    print(f\"‚úÖ Exported: {output_file.name}\")\n",
        "    exported_files.append(output_file)\n",
        "\n",
        "# Create a summary report\n",
        "summary_report = {\n",
        "    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'total_conversations': len(df_conversations_sent) if len(df_conversations_sent) > 0 else 0,\n",
        "    'conversations_with_feedback': len(df_regression) if len(df_regression) > 0 else 0,\n",
        "    'like_ratio': df_regression['like_binary'].mean() if len(df_regression) > 0 else None,\n",
        "    'mean_valence': df_conversations_sent['valence'].mean() if len(df_conversations_sent) > 0 else None,\n",
        "    'mean_arousal': df_conversations_sent['arousal'].mean() if len(df_conversations_sent) > 0 else None,\n",
        "    'mean_dominance': df_conversations_sent['dominance'].mean() if len(df_conversations_sent) > 0 else None,\n",
        "    'model_type': 'Logistic Regression',\n",
        "    'features_used': str(['valence', 'arousal', 'dominance', 'text_length_log', 'word_count_log']),\n",
        "    'test_accuracy': log_model.score(X_test_scaled, y_test) if log_model is not None else None,\n",
        "    'auc_score': auc_score if 'auc_score' in locals() else None\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame([summary_report])\n",
        "output_file = output_dir / 'analysis_summary.csv'\n",
        "summary_df.to_csv(output_file, index=False)\n",
        "print(f\"‚úÖ Exported: {output_file.name}\")\n",
        "exported_files.append(output_file)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Total files exported: {len(exported_files)}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nüìä Analysis Summary:\")\n",
        "print(summary_df.T.to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Additional Analysis Options\n",
        "\n",
        "The cells below provide optional additional analyses you can run based on your needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: Temporal Analysis - How sentiment changes over time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal sentiment analysis\n",
        "if len(df_conversations_sent) > 0 and 'create_time' in df_conversations_sent.columns:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"TEMPORAL SENTIMENT ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Convert to datetime\n",
        "    df_temp = df_conversations_sent.copy()\n",
        "    df_temp['create_time'] = pd.to_datetime(df_temp['create_time'])\n",
        "    df_temp['date'] = df_temp['create_time'].dt.date\n",
        "    df_temp['hour'] = df_temp['create_time'].dt.hour\n",
        "    \n",
        "    # Daily aggregation\n",
        "    daily_sentiment = df_temp.groupby('date').agg({\n",
        "        'valence': 'mean',\n",
        "        'arousal': 'mean',\n",
        "        'dominance': 'mean',\n",
        "        'im_id': 'count'\n",
        "    }).reset_index()\n",
        "    daily_sentiment.columns = ['date', 'valence', 'arousal', 'dominance', 'conversation_count']\n",
        "    \n",
        "    print(f\"\\nDaily sentiment trends:\")\n",
        "    print(daily_sentiment.describe())\n",
        "    \n",
        "    # Plot temporal trends\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Temporal Sentiment Trends', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Daily valence trend\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(daily_sentiment['date'], daily_sentiment['valence'], marker='o', linewidth=2, color='blue')\n",
        "    ax1.set_xlabel('Date')\n",
        "    ax1.set_ylabel('Mean Valence')\n",
        "    ax1.set_title('Valence Over Time')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Daily arousal trend\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.plot(daily_sentiment['date'], daily_sentiment['arousal'], marker='o', linewidth=2, color='green')\n",
        "    ax2.set_xlabel('Date')\n",
        "    ax2.set_ylabel('Mean Arousal')\n",
        "    ax2.set_title('Arousal Over Time')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Daily dominance trend\n",
        "    ax3 = axes[1, 0]\n",
        "    ax3.plot(daily_sentiment['date'], daily_sentiment['dominance'], marker='o', linewidth=2, color='red')\n",
        "    ax3.set_xlabel('Date')\n",
        "    ax3.set_ylabel('Mean Dominance')\n",
        "    ax3.set_title('Dominance Over Time')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Conversation volume\n",
        "    ax4 = axes[1, 1]\n",
        "    ax4.bar(daily_sentiment['date'].astype(str), daily_sentiment['conversation_count'], alpha=0.7, color='purple')\n",
        "    ax4.set_xlabel('Date')\n",
        "    ax4.set_ylabel('Number of Conversations')\n",
        "    ax4.set_title('Conversation Volume Over Time')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    ax4.tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Hourly patterns\n",
        "    hourly_sentiment = df_temp.groupby('hour').agg({\n",
        "        'valence': 'mean',\n",
        "        'arousal': 'mean',\n",
        "        'dominance': 'mean',\n",
        "        'im_id': 'count'\n",
        "    }).reset_index()\n",
        "    \n",
        "    print(f\"\\n‚è∞ Hourly patterns:\")\n",
        "    print(hourly_sentiment)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Temporal analysis not available - missing timestamp data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Interaction Effects Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze interaction effects between sentiment dimensions\n",
        "if len(df_regression) >= 50:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"INTERACTION EFFECTS ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Create interaction terms\n",
        "    df_interact = df_regression[['valence', 'arousal', 'dominance', 'like_binary']].copy()\n",
        "    df_interact['valence_x_arousal'] = df_interact['valence'] * df_interact['arousal']\n",
        "    df_interact['valence_x_dominance'] = df_interact['valence'] * df_interact['dominance']\n",
        "    df_interact['arousal_x_dominance'] = df_interact['arousal'] * df_interact['dominance']\n",
        "    \n",
        "    # Fit model with interactions\n",
        "    X_interact = df_interact[['valence', 'arousal', 'dominance', \n",
        "                               'valence_x_arousal', 'valence_x_dominance', 'arousal_x_dominance']]\n",
        "    y_interact = df_interact['like_binary']\n",
        "    \n",
        "    # Standardize\n",
        "    scaler_interact = StandardScaler()\n",
        "    X_interact_scaled = scaler_interact.fit_transform(X_interact)\n",
        "    \n",
        "    # Fit logistic regression\n",
        "    log_interact = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    log_interact.fit(X_interact_scaled, y_interact)\n",
        "    \n",
        "    # Compare with base model\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(f\"  Base model score: {log_model.score(X_test_scaled, y_test) if log_model else 'N/A':.4f}\")\n",
        "    print(f\"  Interaction model score: {log_interact.score(X_interact_scaled, y_interact):.4f}\")\n",
        "    \n",
        "    # Interaction coefficients\n",
        "    interact_coef = pd.DataFrame({\n",
        "        'Feature': X_interact.columns,\n",
        "        'Coefficient': log_interact.coef_[0],\n",
        "        'Abs_Coefficient': np.abs(log_interact.coef_[0])\n",
        "    }).sort_values('Abs_Coefficient', ascending=False)\n",
        "    \n",
        "    print(\"\\nInteraction Effects:\")\n",
        "    print(interact_coef)\n",
        "    \n",
        "    # Visualize interaction effects\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    fig.suptitle('Sentiment Dimension Interactions', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Valence x Arousal\n",
        "    ax1 = axes[0]\n",
        "    scatter1 = ax1.scatter(df_interact['valence'], df_interact['arousal'], \n",
        "                           c=df_interact['like_binary'], cmap='RdYlGn', alpha=0.6)\n",
        "    ax1.set_xlabel('Valence')\n",
        "    ax1.set_ylabel('Arousal')\n",
        "    ax1.set_title('Valence √ó Arousal')\n",
        "    plt.colorbar(scatter1, ax=ax1, label='Like (1) vs Dislike (0)')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Valence x Dominance\n",
        "    ax2 = axes[1]\n",
        "    scatter2 = ax2.scatter(df_interact['valence'], df_interact['dominance'], \n",
        "                           c=df_interact['like_binary'], cmap='RdYlGn', alpha=0.6)\n",
        "    ax2.set_xlabel('Valence')\n",
        "    ax2.set_ylabel('Dominance')\n",
        "    ax2.set_title('Valence √ó Dominance')\n",
        "    plt.colorbar(scatter2, ax=ax2, label='Like (1) vs Dislike (0)')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Arousal x Dominance\n",
        "    ax3 = axes[2]\n",
        "    scatter3 = ax3.scatter(df_interact['arousal'], df_interact['dominance'], \n",
        "                           c=df_interact['like_binary'], cmap='RdYlGn', alpha=0.6)\n",
        "    ax3.set_xlabel('Arousal')\n",
        "    ax3.set_ylabel('Dominance')\n",
        "    ax3.set_title('Arousal √ó Dominance')\n",
        "    plt.colorbar(scatter3, ax=ax3, label='Like (1) vs Dislike (0)')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nüí° Interpretation:\")\n",
        "    print(\"  Interaction terms show whether the effect of one dimension depends on the level of another.\")\n",
        "    print(\"  Positive coefficients indicate synergistic effects, negative indicate antagonistic effects.\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Insufficient sample size for interaction analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìñ Usage Instructions and Notes\n",
        "\n",
        "### Quick Start\n",
        "1. **Install dependencies**: \n",
        "   ```bash\n",
        "   pip install pandas numpy matplotlib seaborn scikit-learn scipy statsmodels openpyxl\n",
        "   ```\n",
        "   \n",
        "2. **Optional advanced NLP tools** (for better results):\n",
        "   ```bash\n",
        "   pip install transformers torch keybert bertopic\n",
        "   ```\n",
        "\n",
        "3. **Run all cells** from top to bottom\n",
        "\n",
        "### Key Features\n",
        "\n",
        "#### Three-Dimensional Sentiment Analysis\n",
        "- **Valence**: Measures emotional positivity/negativity (-1 to +1)\n",
        "- **Arousal**: Measures emotional intensity/activation (-1 to +1)\n",
        "- **Dominance**: Measures sense of control/power (-1 to +1)\n",
        "\n",
        "#### Regression Models\n",
        "- **Logistic Regression**: Predicts Like/Dislike from sentiment dimensions\n",
        "- **Detailed Statistics**: Uses statsmodels for comprehensive statistical reporting\n",
        "- **Interaction Effects**: Optional analysis of dimension interactions\n",
        "\n",
        "#### Data Exports\n",
        "All results are saved to `analysis_outputs/` directory:\n",
        "- `conversations_with_sentiment.csv`: Full conversation data with VAD scores\n",
        "- `regression_dataset.csv`: Merged dataset for regression analysis\n",
        "- `session_aggregates.csv`: Session-level summary statistics\n",
        "- `sentiment_comparison_stats.csv`: Statistical comparison results\n",
        "- `feature_importance.csv`: Regression coefficients and importance\n",
        "- `analysis_summary.csv`: Overall analysis summary\n",
        "\n",
        "### Customization Options\n",
        "\n",
        "#### Sampling\n",
        "To analyze a subset of data (faster for testing):\n",
        "```python\n",
        "PARAMS['sample_size'] = 10000  # Set in Configuration cell\n",
        "```\n",
        "\n",
        "#### Advanced NLP Models\n",
        "When transformers/keybert are installed, the notebook will automatically:\n",
        "- Use BERT-based models for sentiment analysis\n",
        "- Extract key phrases using KeyBERT\n",
        "- Provide topic modeling capabilities\n",
        "\n",
        "#### Event Analysis\n",
        "When `event_bh.csv` is available, section 5 will analyze:\n",
        "- Pre-conversation events (what triggered the chat)\n",
        "- Post-conversation behaviors (outcomes)\n",
        "- Emotional trajectory correlation with actions\n",
        "\n",
        "### Interpreting Results\n",
        "\n",
        "#### Statistical Significance\n",
        "- `*` p < 0.05\n",
        "- `**` p < 0.01\n",
        "- `***` p < 0.001\n",
        "\n",
        "#### Effect Sizes (Cohen's d)\n",
        "- Small: |d| ‚âà 0.2\n",
        "- Medium: |d| ‚âà 0.5\n",
        "- Large: |d| ‚âà 0.8\n",
        "\n",
        "#### Odds Ratios (OR)\n",
        "- OR > 1: Positive effect on likes\n",
        "- OR < 1: Negative effect on likes\n",
        "- OR = 1: No effect\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "**Issue**: \"No matching records found between feedback and empathy data\"\n",
        "- Check that `im_id` field matches between datasets\n",
        "- Verify date ranges align\n",
        "\n",
        "**Issue**: \"Insufficient data for regression analysis\"\n",
        "- Need at least 30 records with both sentiment scores and feedback\n",
        "- Check data loading and merging steps\n",
        "\n",
        "**Issue**: \"KeyBERT/Transformers not available\"\n",
        "- These are optional - analysis will use lexicon-based methods\n",
        "- Install with pip for enhanced capabilities\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Review the regression results** to identify which sentiment dimensions significantly predict user satisfaction\n",
        "\n",
        "2. **Examine temporal patterns** to understand if sentiment varies by time of day/week\n",
        "\n",
        "3. **Analyze interaction effects** to see if sentiment dimensions work synergistically\n",
        "\n",
        "4. **Integrate event data** (event_bh.csv) when available for complete behavioral analysis\n",
        "\n",
        "5. **Deploy insights** into chatbot improvement strategies\n",
        "\n",
        "### References\n",
        "\n",
        "- **Xu et al. (2025)**: ISR research model for chatbot empathy analysis\n",
        "- **VAD Model**: Valence-Arousal-Dominance emotional dimensions (Russell, 1980)\n",
        "- **Sentiment Analysis**: Lexicon and transformer-based approaches\n",
        "\n",
        "### Contact & Support\n",
        "\n",
        "For questions about this analysis:\n",
        "- Check the comprehensive report in Section 6\n",
        "- Review exported CSV files in `analysis_outputs/`\n",
        "- Examine visualization outputs for patterns\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis Framework Version**: 1.0  \n",
        "**Created**: November 2025  \n",
        "**Python**: 3.8+  \n",
        "**License**: For research and internal use\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
