{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Beihai AI Companion Dialogue Empathy Analysis\n",
        "\n",
        "## Analysis Overview\n",
        "This notebook analyzes empathy expressions in Beihai AI companion dialogues and their correlation with user feedback (likes/dislikes). The analysis focuses on three empathy dimensions:\n",
        "\n",
        "1. **Perspective Taking (è§†è§’é‡‡æ‹©)**: Understanding and acknowledging user's viewpoint\n",
        "2. **Concern to Help (ä¸»åŠ¨å¸®åŠ©)**: Willingness to provide assistance and guidance\n",
        "3. **Affective Empathy (æƒ…æ„Ÿå…±é¸£)**: Emotional understanding and resonance\n",
        "\n",
        "## Data Sources\n",
        "- Conversation data: 4 Excel files (May-July 2024)\n",
        "- Feedback data: CSV file with likes/dislikes and reasons\n",
        "- Focus: Beihai data (travel_id = 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data-analysis/lib/python3.9/site-packages/sklearn/linear_model/__init__.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ARDRegression, BayesianRidge\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ElasticNet,\n\u001b[1;32m     14\u001b[0m     ElasticNetCV,\n\u001b[1;32m     15\u001b[0m     Lasso,\n\u001b[1;32m     16\u001b[0m     LassoCV,\n\u001b[1;32m     17\u001b[0m     MultiTaskElasticNet,\n\u001b[1;32m     18\u001b[0m     MultiTaskElasticNetCV,\n\u001b[1;32m     19\u001b[0m     MultiTaskLasso,\n\u001b[1;32m     20\u001b[0m     MultiTaskLassoCV,\n\u001b[1;32m     21\u001b[0m     enet_path,\n\u001b[1;32m     22\u001b[0m     lasso_path,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_glm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GammaRegressor, PoissonRegressor, TweedieRegressor\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_huber\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data-analysis/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:44\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     _check_sample_weight,\n\u001b[1;32m     35\u001b[0m     check_consistent_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     validate_data,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# mypy error: Module 'sklearn.linear_model' has no attribute '_cd_fast'\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _cd_fast \u001b[38;5;28;01mas\u001b[39;00m cd_fast  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearModel, _pre_fit, _preprocess_data\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_order\u001b[39m(X, y, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import datetime\n",
        "from scipy import stats\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up Chinese font support for matplotlib\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Analysis started at: {datetime.datetime.now()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define empathy keywords for three dimensions\n",
        "EMPATHY_KEYWORDS = {\n",
        "    'perspective_taking': [\n",
        "        'ä½ æ˜¯', 'ä½ æƒ³', 'ä½ çš„', 'æ ¹æ®ä½ ', 'å¯¹äºŽä½ ', 'ä½ å¯èƒ½', 'ä½ å¸Œæœ›', \n",
        "        'ä½ è§‰å¾—', 'ä½ è®¤ä¸º', 'ä½ éœ€è¦', 'ä»Žä½ çš„è§’åº¦', 'ç«™åœ¨ä½ çš„', 'ç†è§£ä½ çš„',\n",
        "        'ä½ ä¼š', 'ä½ åº”è¯¥', 'ä½ æåˆ°', 'ä½ è¯´çš„', 'ä½ å…³å¿ƒ', 'ä½ æ‹…å¿ƒ', 'ä½ æœŸæœ›'\n",
        "    ],\n",
        "    'concern_to_help': [\n",
        "        'å»ºè®®', 'æŽ¨è', 'å¸®ä½ ', 'ä¸ºä½ ', 'ç»™ä½ ', 'ååŠ©', 'æŒ‡å¯¼', 'æ”¯æŒ',\n",
        "        'è§£å†³', 'æä¾›', 'å®‰æŽ’', 'è§„åˆ’', 'åˆ¶å®š', 'æ•´ç†', 'å‡†å¤‡',\n",
        "        'å¯ä»¥è¯•è¯•', 'ä¸å¦¨', 'æˆ–è®¸å¯ä»¥', 'å»ºè®®ä½ ', 'æŽ¨èä½ ', 'å¸®åŠ©ä½ '\n",
        "    ],\n",
        "    'affective_empathy': [\n",
        "        'åˆ«ç€æ€¥', 'ä¸è¦æ‹…å¿ƒ', 'æ”¾å¿ƒ', 'ç†è§£', 'æ„Ÿå—', 'ä½“ä¼š', 'å…±é¸£',\n",
        "        'åŒæ„Ÿ', 'å¿ƒæƒ…', 'æ„Ÿè§‰', 'æƒ…ç»ª', 'å¼€å¿ƒ', 'é«˜å…´', 'æ»¡æ„',\n",
        "        'é—æ†¾', 'å¯æƒœ', 'æŠ±æ­‰', 'æ­‰æ„', 'æ¸©é¦¨', 'è´´å¿ƒ', 'æš–å¿ƒ', 'ç†è§£æ‚¨'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Define file paths\n",
        "FEEDBACK_PATH = '/Users/ericwang/git/mics/empathy/å›žç­”åé¦ˆ.csv'\n",
        "EXCEL_FILES = [\n",
        "    '/Users/ericwang/git/mics/empathy/åŒ—æµ·æ™ºä¼´å¯¹è¯_250501-0520.xlsx',\n",
        "    '/Users/ericwang/git/mics/empathy/åŒ—æµ·æ™ºä¼´å¯¹è¯_250521-0610.xlsx',\n",
        "    '/Users/ericwang/git/mics/empathy/åŒ—æµ·æ™ºä¼´å¯¹è¯_250611-0620.xlsx',\n",
        "    '/Users/ericwang/git/mics/empathy/åŒ—æµ·æ™ºä¼´å¯¹è¯_250621-0701.xlsx'\n",
        "]\n",
        "\n",
        "print(\"Configuration completed!\")\n",
        "print(f\"Empathy dimensions: {list(EMPATHY_KEYWORDS.keys())}\")\n",
        "print(f\"Data files: {len(EXCEL_FILES)} Excel files + 1 CSV file\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Data Loading and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_feedback_data(feedback_path):\n",
        "    \"\"\"Load and preprocess feedback data\"\"\"\n",
        "    print(\"Loading feedback data...\")\n",
        "    df_feedback = pd.read_csv(feedback_path)\n",
        "    \n",
        "    print(f\"Original feedback records: {len(df_feedback)}\")\n",
        "    \n",
        "    # Filter Beihai data (travel_id=40)\n",
        "    df_feedback = df_feedback[df_feedback['travel_id'] == 40].copy()\n",
        "    print(f\"Beihai feedback records: {len(df_feedback)}\")\n",
        "    \n",
        "    # Filter valid feedback states (1: like, 2: dislike, 0: cancelled)\n",
        "    df_feedback = df_feedback[df_feedback['feedback_state'].isin([1, 2])].copy()\n",
        "    print(f\"Valid feedback records (likes/dislikes): {len(df_feedback)}\")\n",
        "    \n",
        "    # Show feedback distribution\n",
        "    feedback_counts = df_feedback['feedback_state'].value_counts()\n",
        "    print(f\"\\nFeedback distribution:\")\n",
        "    print(f\"  Likes (feedback_state=1): {feedback_counts.get(1, 0)}\")\n",
        "    print(f\"  Dislikes (feedback_state=2): {feedback_counts.get(2, 0)}\")\n",
        "    \n",
        "    return df_feedback\n",
        "\n",
        "# Load feedback data\n",
        "df_feedback = load_feedback_data(FEEDBACK_PATH)\n",
        "df_feedback.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_conversation_data(excel_files):\n",
        "    \"\"\"Load and combine conversation data from multiple Excel files\"\"\"\n",
        "    print(\"Loading conversation data...\")\n",
        "    all_conversations = []\n",
        "    \n",
        "    for file_path in excel_files:\n",
        "        print(f\"Processing: {file_path.split('/')[-1]}\")\n",
        "        try:\n",
        "            df = pd.read_excel(file_path)\n",
        "            # Filter Beihai data (travel_id=40)\n",
        "            df_filtered = df[df['travel_id'] == 40].copy()\n",
        "            all_conversations.append(df_filtered)\n",
        "            print(f\"  Records: {len(df_filtered):,}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error loading {file_path}: {e}\")\n",
        "    \n",
        "    if all_conversations:\n",
        "        df_all = pd.concat(all_conversations, ignore_index=True)\n",
        "        # Remove rows with empty content (correct column name is 'im_content')\n",
        "        df_all = df_all.dropna(subset=['im_content']).copy()\n",
        "        # Remove rows with empty or whitespace-only content\n",
        "        df_all = df_all[df_all['im_content'].str.strip() != ''].copy()\n",
        "        print(f\"\\nTotal conversation records after cleaning: {len(df_all):,}\")\n",
        "        return df_all\n",
        "    else:\n",
        "        print(\"No conversation data loaded successfully\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Load conversation data\n",
        "df_conversations = load_conversation_data(EXCEL_FILES)\n",
        "print(f\"\\nConversation data shape: {df_conversations.shape}\")\n",
        "print(f\"Columns: {df_conversations.columns.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Empathy Analysis Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_empathy_scores(text):\n",
        "    \"\"\"Calculate empathy scores for a given text across three dimensions\"\"\"\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return {\n",
        "            'perspective_taking': 0, \n",
        "            'concern_to_help': 0, \n",
        "            'affective_empathy': 0, \n",
        "            'total_empathy': 0\n",
        "        }\n",
        "    \n",
        "    text_lower = text.lower()\n",
        "    scores = {}\n",
        "    \n",
        "    for dimension, keywords in EMPATHY_KEYWORDS.items():\n",
        "        score = 0\n",
        "        for keyword in keywords:\n",
        "            # Count occurrences of each keyword\n",
        "            score += text_lower.count(keyword.lower())\n",
        "        scores[dimension] = score\n",
        "    \n",
        "    # Calculate total empathy score\n",
        "    scores['total_empathy'] = sum(scores.values())\n",
        "    \n",
        "    return scores\n",
        "\n",
        "def analyze_empathy_in_conversations(df_conversations, sample_size=None):\n",
        "    \"\"\"Analyze empathy expressions in conversation data\"\"\"\n",
        "    print(\"Analyzing empathy expressions in conversations...\")\n",
        "    \n",
        "    # Sample data if specified (for faster processing during development)\n",
        "    if sample_size and len(df_conversations) > sample_size:\n",
        "        df_sample = df_conversations.sample(n=sample_size, random_state=42)\n",
        "        print(f\"Analyzing sample of {sample_size:,} records from {len(df_conversations):,} total\")\n",
        "    else:\n",
        "        df_sample = df_conversations\n",
        "        print(f\"Analyzing all {len(df_sample):,} records\")\n",
        "    \n",
        "    empathy_scores = []\n",
        "    total_records = len(df_sample)\n",
        "    \n",
        "    for idx, row in df_sample.iterrows():\n",
        "        if len(empathy_scores) % 10000 == 0 and len(empathy_scores) > 0:\n",
        "            print(f\"  Processed: {len(empathy_scores):,}/{total_records:,} ({len(empathy_scores)/total_records*100:.1f}%)\")\n",
        "        \n",
        "        scores = calculate_empathy_scores(row['im_content'])\n",
        "        scores.update({\n",
        "            'im_id': row['im_id'],\n",
        "            'session_id': row['session_id'],\n",
        "            'im_type': row.get('im_type', 'unknown'),\n",
        "            'content': row['im_content'],\n",
        "            'content_length': len(str(row['im_content'])),\n",
        "            'create_time': row['create_time']\n",
        "        })\n",
        "        empathy_scores.append(scores)\n",
        "    \n",
        "    df_empathy = pd.DataFrame(empathy_scores)\n",
        "    print(f\"\\nEmpathy analysis completed: {len(df_empathy):,} records\")\n",
        "    \n",
        "    return df_empathy\n",
        "\n",
        "# Test empathy calculation with sample text\n",
        "sample_text = \"æˆ‘å»ºè®®ä½ å¯ä»¥åŽ»æ¶ æ´²å²›çœ‹çœ‹ï¼Œé‚£é‡Œå¾ˆé€‚åˆä½ çš„æ—…è¡Œè®¡åˆ’ã€‚ä½ è§‰å¾—æ€Žä¹ˆæ ·ï¼Ÿ\"\n",
        "sample_scores = calculate_empathy_scores(sample_text)\n",
        "print(\"Sample empathy calculation:\")\n",
        "print(f\"Text: {sample_text}\")\n",
        "print(f\"Scores: {sample_scores}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze empathy in conversations (using sample for faster processing)\n",
        "# For full analysis, set sample_size=None\n",
        "SAMPLE_SIZE = 50000  # Adjust based on computational resources\n",
        "\n",
        "df_empathy = analyze_empathy_in_conversations(df_conversations, sample_size=SAMPLE_SIZE)\n",
        "\n",
        "# Display empathy analysis summary\n",
        "print(\"\\nEmpathy Analysis Summary:\")\n",
        "for dimension in ['perspective_taking', 'concern_to_help', 'affective_empathy', 'total_empathy']:\n",
        "    scores = df_empathy[dimension]\n",
        "    print(f\"\\n{dimension}:\")\n",
        "    print(f\"  Mean: {scores.mean():.3f}\")\n",
        "    print(f\"  Std: {scores.std():.3f}\")\n",
        "    print(f\"  Max: {scores.max()}\")\n",
        "    print(f\"  Records with score > 0: {(scores > 0).sum():,} ({(scores > 0).mean()*100:.1f}%)\")\n",
        "\n",
        "# Show top empathy examples\n",
        "print(\"\\n=== Top Empathy Examples ===\")\n",
        "top_empathy = df_empathy.nlargest(5, 'total_empathy')[['total_empathy', 'perspective_taking', 'concern_to_help', 'affective_empathy', 'content']]\n",
        "for idx, row in top_empathy.iterrows():\n",
        "    print(f\"\\nTotal Score: {row['total_empathy']} (PT:{row['perspective_taking']}, CH:{row['concern_to_help']}, AE:{row['affective_empathy']})\")\n",
        "    print(f\"Content: {row['content'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Data Integration and Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_feedback_and_empathy(df_feedback, df_empathy):\n",
        "    \"\"\"Merge feedback data with empathy analysis results\"\"\"\n",
        "    print(\"Merging feedback and empathy data...\")\n",
        "    \n",
        "    # Merge on im_id\n",
        "    df_merged = pd.merge(df_feedback, df_empathy, on='im_id', how='inner')\n",
        "    \n",
        "    print(f\"Merged dataset size: {len(df_merged):,} records\")\n",
        "    \n",
        "    if len(df_merged) == 0:\n",
        "        print(\"WARNING: No matching records found between feedback and empathy data!\")\n",
        "        print(\"\\nChecking im_id overlap:\")\n",
        "        feedback_ids = set(df_feedback['im_id'].dropna())\n",
        "        empathy_ids = set(df_empathy['im_id'].dropna())\n",
        "        print(f\"Feedback unique im_ids: {len(feedback_ids):,}\")\n",
        "        print(f\"Empathy unique im_ids: {len(empathy_ids):,}\")\n",
        "        print(f\"Overlapping im_ids: {len(feedback_ids.intersection(empathy_ids)):,}\")\n",
        "        return df_merged\n",
        "    \n",
        "    # Create binary label (1: like, 0: dislike)\n",
        "    df_merged['like_binary'] = (df_merged['feedback_state'] == 1).astype(int)\n",
        "    \n",
        "    # Show merge results\n",
        "    print(f\"\\nMerge Results:\")\n",
        "    print(f\"  Likes: {(df_merged['like_binary'] == 1).sum():,}\")\n",
        "    print(f\"  Dislikes: {(df_merged['like_binary'] == 0).sum():,}\")\n",
        "    print(f\"  Like ratio: {df_merged['like_binary'].mean():.3f}\")\n",
        "    \n",
        "    return df_merged\n",
        "\n",
        "# Merge the datasets\n",
        "df_merged = merge_feedback_and_empathy(df_feedback, df_empathy)\n",
        "\n",
        "if len(df_merged) > 0:\n",
        "    print(\"\\nMerged dataset preview:\")\n",
        "    display(df_merged[['im_id', 'feedback_state', 'like_binary', 'perspective_taking', \n",
        "                      'concern_to_help', 'affective_empathy', 'total_empathy']].head(10))\n",
        "else:\n",
        "    print(\"Cannot proceed with analysis due to no matching data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical Analysis\n",
        "if len(df_merged) > 0:\n",
        "    print(\"=== Descriptive Statistics by Feedback Type ===\")\n",
        "    \n",
        "    empathy_cols = ['perspective_taking', 'concern_to_help', 'affective_empathy', 'total_empathy']\n",
        "    \n",
        "    stats_summary = []\n",
        "    for col in empathy_cols:\n",
        "        like_data = df_merged[df_merged['like_binary'] == 1][col]\n",
        "        dislike_data = df_merged[df_merged['like_binary'] == 0][col]\n",
        "        \n",
        "        # Statistical test (Mann-Whitney U test for non-parametric comparison)\n",
        "        if len(like_data) > 0 and len(dislike_data) > 0:\n",
        "            try:\n",
        "                statistic, p_value = stats.mannwhitneyu(like_data, dislike_data, alternative='two-sided')\n",
        "            except:\n",
        "                p_value = 1.0  # If test fails, assume no significance\n",
        "        else:\n",
        "            p_value = 1.0\n",
        "        \n",
        "        stats_summary.append({\n",
        "            'Dimension': col,\n",
        "            'Like_Mean': like_data.mean(),\n",
        "            'Like_Std': like_data.std(),\n",
        "            'Dislike_Mean': dislike_data.mean(),\n",
        "            'Dislike_Std': dislike_data.std(),\n",
        "            'Mean_Diff': like_data.mean() - dislike_data.mean(),\n",
        "            'P_Value': p_value,\n",
        "            'Significant': p_value < 0.05\n",
        "        })\n",
        "    \n",
        "    stats_df = pd.DataFrame(stats_summary)\n",
        "    display(stats_df.round(4))\n",
        "    \n",
        "    # Show significant differences\n",
        "    significant_dims = stats_df[stats_df['Significant']]['Dimension'].tolist()\n",
        "    if significant_dims:\n",
        "        print(f\"\\nâœ… Statistically significant differences found in: {significant_dims}\")\n",
        "    else:\n",
        "        print(f\"\\nâž¡ï¸ No statistically significant differences found between like/dislike groups.\")\n",
        "        \n",
        "    # Correlation analysis\n",
        "    print(f\"\\n=== Correlation Analysis ===\")\n",
        "    for col in empathy_cols:\n",
        "        corr = df_merged[col].corr(df_merged['like_binary'])\n",
        "        print(f\"{col}: {corr:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping statistical analysis due to no merged data.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Data Visualization and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df_merged) > 0:\n",
        "    # Create comprehensive visualizations\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('Empathy Analysis Results - Beihai AI Companion Dialogues', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Empathy scores comparison by feedback type\n",
        "    ax1 = axes[0, 0]\n",
        "    empathy_dims = ['perspective_taking', 'concern_to_help', 'affective_empathy']\n",
        "    dim_labels = ['Perspective\\nTaking', 'Concern to\\nHelp', 'Affective\\nEmpathy']\n",
        "    \n",
        "    like_means = [df_merged[df_merged['like_binary'] == 1][dim].mean() for dim in empathy_dims]\n",
        "    dislike_means = [df_merged[df_merged['like_binary'] == 0][dim].mean() for dim in empathy_dims]\n",
        "    \n",
        "    x = np.arange(len(empathy_dims))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax1.bar(x - width/2, like_means, width, label='Likes', alpha=0.8, color='skyblue')\n",
        "    ax1.bar(x + width/2, dislike_means, width, label='Dislikes', alpha=0.8, color='lightcoral')\n",
        "    \n",
        "    ax1.set_xlabel('Empathy Dimensions')\n",
        "    ax1.set_ylabel('Average Score')\n",
        "    ax1.set_title('Empathy Scores by Feedback Type')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(dim_labels)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Total empathy distribution\n",
        "    ax2 = axes[0, 1]\n",
        "    like_total = df_merged[df_merged['like_binary'] == 1]['total_empathy']\n",
        "    dislike_total = df_merged[df_merged['like_binary'] == 0]['total_empathy']\n",
        "    \n",
        "    ax2.hist(like_total, alpha=0.7, label='Likes', bins=15, color='skyblue', density=True)\n",
        "    ax2.hist(dislike_total, alpha=0.7, label='Dislikes', bins=15, color='lightcoral', density=True)\n",
        "    ax2.set_xlabel('Total Empathy Score')\n",
        "    ax2.set_ylabel('Density')\n",
        "    ax2.set_title('Total Empathy Score Distribution')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Correlation heatmap\n",
        "    ax3 = axes[0, 2]\n",
        "    corr_cols = ['perspective_taking', 'concern_to_help', 'affective_empathy', 'total_empathy', 'like_binary']\n",
        "    corr_matrix = df_merged[corr_cols].corr()\n",
        "    \n",
        "    im = ax3.imshow(corr_matrix, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
        "    ax3.set_xticks(range(len(corr_cols)))\n",
        "    ax3.set_yticks(range(len(corr_cols)))\n",
        "    ax3.set_xticklabels(['PT', 'CH', 'AE', 'Total', 'Like'], rotation=45)\n",
        "    ax3.set_yticklabels(['PT', 'CH', 'AE', 'Total', 'Like'])\n",
        "    ax3.set_title('Feature Correlation Matrix')\n",
        "    \n",
        "    # Add correlation values\n",
        "    for i in range(len(corr_cols)):\n",
        "        for j in range(len(corr_cols)):\n",
        "            ax3.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
        "                    ha='center', va='center', fontsize=8)\n",
        "    \n",
        "    plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "    \n",
        "    # 4. Feedback distribution pie chart\n",
        "    ax4 = axes[1, 0]\n",
        "    feedback_counts = df_merged['like_binary'].value_counts()\n",
        "    labels = ['Dislikes', 'Likes']\n",
        "    colors = ['lightcoral', 'skyblue']\n",
        "    \n",
        "    ax4.pie([feedback_counts[0], feedback_counts[1]], labels=labels, autopct='%1.1f%%', \n",
        "            colors=colors, startangle=90)\n",
        "    ax4.set_title('Feedback Distribution')\n",
        "    \n",
        "    # 5. Box plot of empathy dimensions\n",
        "    ax5 = axes[1, 1]\n",
        "    empathy_data_likes = [df_merged[df_merged['like_binary'] == 1][dim].values for dim in empathy_dims]\n",
        "    empathy_data_dislikes = [df_merged[df_merged['like_binary'] == 0][dim].values for dim in empathy_dims]\n",
        "    \n",
        "    positions = np.arange(1, len(empathy_dims) * 2, 2)\n",
        "    bp1 = ax5.boxplot(empathy_data_likes, positions=positions - 0.2, widths=0.3, patch_artist=True)\n",
        "    bp2 = ax5.boxplot(empathy_data_dislikes, positions=positions + 0.2, widths=0.3, patch_artist=True)\n",
        "    \n",
        "    for patch in bp1['boxes']:\n",
        "        patch.set_facecolor('skyblue')\n",
        "    for patch in bp2['boxes']:\n",
        "        patch.set_facecolor('lightcoral')\n",
        "    \n",
        "    ax5.set_xlabel('Empathy Dimensions')\n",
        "    ax5.set_ylabel('Empathy Score')\n",
        "    ax5.set_title('Empathy Score Distributions')\n",
        "    ax5.set_xticks(positions)\n",
        "    ax5.set_xticklabels(['PT', 'CH', 'AE'])\n",
        "    ax5.legend([bp1['boxes'][0], bp2['boxes'][0]], ['Likes', 'Dislikes'])\n",
        "    \n",
        "    # 6. Empathy threshold analysis\n",
        "    ax6 = axes[1, 2]\n",
        "    thresholds = range(0, int(df_merged['total_empathy'].max()) + 1)\n",
        "    like_rates = []\n",
        "    sample_sizes = []\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "        high_empathy = df_merged[df_merged['total_empathy'] >= threshold]\n",
        "        if len(high_empathy) > 0:\n",
        "            like_rate = high_empathy['like_binary'].mean()\n",
        "            like_rates.append(like_rate)\n",
        "            sample_sizes.append(len(high_empathy))\n",
        "        else:\n",
        "            like_rates.append(0)\n",
        "            sample_sizes.append(0)\n",
        "    \n",
        "    ax6.plot(thresholds, like_rates, marker='o', linewidth=2, color='green')\n",
        "    ax6.set_xlabel('Empathy Threshold')\n",
        "    ax6.set_ylabel('Like Rate')\n",
        "    ax6.set_title('Like Rate vs Empathy Threshold')\n",
        "    ax6.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add sample size annotations\n",
        "    for i, (threshold, rate, size) in enumerate(zip(thresholds, like_rates, sample_sizes)):\n",
        "        if i % 2 == 0 and size > 10:  # Show every other point with sufficient sample size\n",
        "            ax6.annotate(f'n={size}', (threshold, rate), textcoords=\"offset points\", \n",
        "                        xytext=(0,10), ha='center', fontsize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot create visualizations due to no merged data.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Logistic Regression Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df_merged) >= 20:  # Need minimum samples for regression\n",
        "    print(\"=== Logistic Regression Analysis ===\")\n",
        "    \n",
        "    # Prepare features and target\n",
        "    feature_cols = ['perspective_taking', 'concern_to_help', 'affective_empathy', 'total_empathy']\n",
        "    X = df_merged[feature_cols]\n",
        "    y = df_merged['like_binary']\n",
        "    \n",
        "    print(f\"Feature matrix shape: {X.shape}\")\n",
        "    print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    # Split data if we have enough samples\n",
        "    if len(X) >= 40:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        print(f\"Training set: {len(X_train)}, Test set: {len(X_test)}\")\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = X_scaled, X_scaled, y, y\n",
        "        print(\"Using full dataset for training due to small sample size\")\n",
        "    \n",
        "    # Train logistic regression model\n",
        "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Model evaluation\n",
        "    print(\"\\\\n=== Model Performance ===\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Dislike', 'Like']))\n",
        "    \n",
        "    print(\"\\\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "    \n",
        "    # Feature importance\n",
        "    print(\"\\\\n=== Feature Importance (Logistic Regression Coefficients) ===\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_cols,\n",
        "        'Coefficient': model.coef_[0],\n",
        "        'Abs_Coefficient': np.abs(model.coef_[0])\n",
        "    }).sort_values('Abs_Coefficient', ascending=False)\n",
        "    \n",
        "    display(feature_importance)\n",
        "    \n",
        "    print(f\"\\\\nModel Intercept: {model.intercept_[0]:.4f}\")\n",
        "    \n",
        "    # ROC curve and AUC if we have both classes in test set\n",
        "    if len(np.unique(y_test)) > 1:\n",
        "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "        print(f\"AUC Score: {auc_score:.4f}\")\n",
        "        \n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        \n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.3f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curve - Empathy vs User Feedback')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "    \n",
        "    # Feature importance visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(feature_importance['Feature'], feature_importance['Coefficient'], \n",
        "            color=['skyblue' if x > 0 else 'lightcoral' for x in feature_importance['Coefficient']])\n",
        "    plt.xlabel('Empathy Dimensions')\n",
        "    plt.ylabel('Logistic Regression Coefficient')\n",
        "    plt.title('Feature Importance in Predicting User Likes')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"Insufficient data for logistic regression analysis.\")\n",
        "    print(f\"Current sample size: {len(df_merged)}, minimum required: 20\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Comprehensive Analysis Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive analysis report\n",
        "if len(df_merged) > 0:\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"                    EMPATHY ANALYSIS REPORT\")\n",
        "    print(\"                 Beihai AI Companion Dialogues\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Executive Summary\n",
        "    print(\"\\\\nðŸ” EXECUTIVE SUMMARY\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"â€¢ Dataset Size: {len(df_merged):,} analyzed conversations with feedback\")\n",
        "    print(f\"â€¢ Analysis Period: {df_merged['create_time'].min()} to {df_merged['create_time'].max()}\")\n",
        "    print(f\"â€¢ Overall Like Rate: {df_merged['like_binary'].mean():.1%}\")\n",
        "    print(f\"â€¢ Average Total Empathy Score: {df_merged['total_empathy'].mean():.2f}\")\n",
        "    \n",
        "    # Key Findings\n",
        "    print(\"\\\\nðŸ“Š KEY FINDINGS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # 1. Empathy-Feedback Correlation\n",
        "    empathy_like_corr = df_merged['total_empathy'].corr(df_merged['like_binary'])\n",
        "    print(f\"1. Total Empathy vs Like Correlation: {empathy_like_corr:.3f}\")\n",
        "    \n",
        "    if empathy_like_corr > 0.1:\n",
        "        print(\"   âœ… Positive correlation found - Higher empathy tends to receive more likes\")\n",
        "    elif empathy_like_corr < -0.1:\n",
        "        print(\"   âš ï¸ Negative correlation found - Higher empathy tends to receive fewer likes\")\n",
        "    else:\n",
        "        print(\"   âž¡ï¸ Weak correlation - Empathy may not strongly predict user satisfaction\")\n",
        "    \n",
        "    # 2. Dimension Analysis\n",
        "    print(\"\\\\n2. Empathy Dimension Performance:\")\n",
        "    for dim in ['perspective_taking', 'concern_to_help', 'affective_empathy']:\n",
        "        dim_corr = df_merged[dim].corr(df_merged['like_binary'])\n",
        "        like_avg = df_merged[df_merged['like_binary'] == 1][dim].mean()\n",
        "        dislike_avg = df_merged[df_merged['like_binary'] == 0][dim].mean()\n",
        "        print(f\"   â€¢ {dim}: Correlation={dim_corr:.3f}, Like_avg={like_avg:.2f}, Dislike_avg={dislike_avg:.2f}\")\n",
        "    \n",
        "    # 3. Statistical Significance\n",
        "    if 'stats_df' in locals() and len(stats_df) > 0:\n",
        "        significant_dims = stats_df[stats_df['Significant']]['Dimension'].tolist()\n",
        "        print(f\"\\\\n3. Statistically Significant Dimensions: {len(significant_dims)}\")\n",
        "        for dim in significant_dims:\n",
        "            row = stats_df[stats_df['Dimension'] == dim].iloc[0]\n",
        "            print(f\"   â€¢ {dim}: Mean difference = {row['Mean_Diff']:.3f} (p={row['P_Value']:.4f})\")\n",
        "    \n",
        "    # 4. Content Insights\n",
        "    high_empathy_threshold = df_merged['total_empathy'].quantile(0.75)\n",
        "    high_empathy_like_rate = df_merged[df_merged['total_empathy'] >= high_empathy_threshold]['like_binary'].mean()\n",
        "    low_empathy_like_rate = df_merged[df_merged['total_empathy'] < high_empathy_threshold]['like_binary'].mean()\n",
        "    \n",
        "    print(f\"\\\\n4. Content Analysis:\")\n",
        "    print(f\"   â€¢ High Empathy (â‰¥75th percentile) Like Rate: {high_empathy_like_rate:.1%}\")\n",
        "    print(f\"   â€¢ Low Empathy (<75th percentile) Like Rate: {low_empathy_like_rate:.1%}\")\n",
        "    print(f\"   â€¢ Difference: {high_empathy_like_rate - low_empathy_like_rate:.1%}\")\n",
        "    \n",
        "    # Recommendations\n",
        "    print(\"\\\\nðŸ’¡ STRATEGIC RECOMMENDATIONS\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    print(\"1. ðŸŽ¯ EMPATHY OPTIMIZATION:\")\n",
        "    if empathy_like_corr > 0.1:\n",
        "        print(\"   â€¢ Increase empathy expressions in AI responses\")\n",
        "        print(\"   â€¢ Focus on training models to be more empathetic\")\n",
        "    else:\n",
        "        print(\"   â€¢ Empathy alone may not drive satisfaction - investigate other factors\")\n",
        "        print(\"   â€¢ Balance empathy with accuracy and helpfulness\")\n",
        "    \n",
        "    print(\"\\\\n2. ðŸ“ CONTENT STRATEGY:\")\n",
        "    if 'stats_df' in locals() and len(stats_df) > 0 and len(stats_df[stats_df['Significant']]) > 0:\n",
        "        best_dim = stats_df.loc[stats_df['Mean_Diff'].idxmax(), 'Dimension']\n",
        "        print(f\"   â€¢ Prioritize '{best_dim}' - shows strongest positive impact\")\n",
        "    \n",
        "    print(\"   â€¢ Optimize response length for better empathy integration\")\n",
        "    print(\"   â€¢ Develop templates that naturally incorporate empathy\")\n",
        "    \n",
        "    print(\"\\\\n3. ðŸ”§ TECHNICAL IMPROVEMENTS:\")\n",
        "    print(\"   â€¢ Implement empathy scoring in real-time response evaluation\")\n",
        "    print(\"   â€¢ Create empathy-aware response ranking algorithms\")\n",
        "    print(\"   â€¢ Develop A/B testing framework for empathy variations\")\n",
        "    \n",
        "    print(\"\\\\n4. ðŸ“ˆ MONITORING & EVALUATION:\")\n",
        "    print(\"   â€¢ Establish empathy score benchmarks for different conversation types\")\n",
        "    print(\"   â€¢ Monitor empathy trends over time\")\n",
        "    print(\"   â€¢ Track correlation between empathy improvements and user satisfaction\")\n",
        "    \n",
        "    # Limitations\n",
        "    print(\"\\\\nâš ï¸ ANALYSIS LIMITATIONS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"â€¢ Keyword-based empathy detection may miss nuanced expressions\")\n",
        "    print(\"â€¢ Sample size and time period constraints\")\n",
        "    print(\"â€¢ Correlation does not imply causation\")\n",
        "    print(\"â€¢ User feedback may be influenced by factors beyond empathy\")\n",
        "    \n",
        "    # Future Research\n",
        "    print(\"\\\\nðŸ”¬ FUTURE RESEARCH DIRECTIONS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"â€¢ Implement advanced NLP models for empathy detection\")\n",
        "    print(\"â€¢ Conduct longitudinal analysis with larger datasets\")\n",
        "    print(\"â€¢ Investigate interaction effects between empathy and content quality\")\n",
        "    print(\"â€¢ Develop user-specific empathy preference models\")\n",
        "    \n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(f\"Report generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "else:\n",
        "    print(\"\\\\nâš ï¸ ANALYSIS INCOMPLETE\")\n",
        "    print(\"No merged data available for comprehensive analysis.\")\n",
        "    print(\"Please check data loading and merging procedures.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Data Export and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results and create summary\n",
        "if len(df_merged) > 0:\n",
        "    # Export main analysis dataset\n",
        "    output_file = '/Users/ericwang/git/mics/empathy/empathy_analysis_results.csv'\n",
        "    df_merged.to_csv(output_file, index=False)\n",
        "    print(f\"âœ… Analysis results exported to: {output_file}\")\n",
        "    \n",
        "    # Create summary statistics file\n",
        "    summary_stats = {\n",
        "        'metric': [\n",
        "            'total_conversations_analyzed',\n",
        "            'total_feedback_records',\n",
        "            'like_count',\n",
        "            'dislike_count',\n",
        "            'overall_like_rate',\n",
        "            'avg_perspective_taking_score',\n",
        "            'avg_concern_to_help_score', \n",
        "            'avg_affective_empathy_score',\n",
        "            'avg_total_empathy_score',\n",
        "            'empathy_like_correlation'\n",
        "        ],\n",
        "        'value': [\n",
        "            len(df_merged),\n",
        "            len(df_merged),\n",
        "            (df_merged['like_binary'] == 1).sum(),\n",
        "            (df_merged['like_binary'] == 0).sum(),\n",
        "            df_merged['like_binary'].mean(),\n",
        "            df_merged['perspective_taking'].mean(),\n",
        "            df_merged['concern_to_help'].mean(),\n",
        "            df_merged['affective_empathy'].mean(),\n",
        "            df_merged['total_empathy'].mean(),\n",
        "            df_merged['total_empathy'].corr(df_merged['like_binary'])\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    summary_df = pd.DataFrame(summary_stats)\n",
        "    summary_file = '/Users/ericwang/git/mics/empathy/analysis_summary.csv'\n",
        "    summary_df.to_csv(summary_file, index=False)\n",
        "    print(f\"âœ… Summary statistics exported to: {summary_file}\")\n",
        "    \n",
        "    # Display final summary\n",
        "    print(\"\\\\nðŸ“‹ FINAL ANALYSIS SUMMARY:\")\n",
        "    display(summary_df)\n",
        "    \n",
        "    # Create empathy examples file\n",
        "    if len(df_empathy) > 0:\n",
        "        top_empathy_examples = df_empathy.nlargest(20, 'total_empathy')[\n",
        "            ['total_empathy', 'perspective_taking', 'concern_to_help', 'affective_empathy', 'content']\n",
        "        ]\n",
        "        examples_file = '/Users/ericwang/git/mics/empathy/top_empathy_examples.csv'\n",
        "        top_empathy_examples.to_csv(examples_file, index=False)\n",
        "        print(f\"âœ… Top empathy examples exported to: {examples_file}\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ No data available for export.\")\n",
        "\n",
        "print(\"\\\\nðŸŽ‰ Analysis completed successfully!\")\n",
        "print(f\"Notebook execution finished at: {datetime.datetime.now()}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. ISR Research Model Integration\n",
        "\n",
        "### 8.1 Theoretical Framework Integration\n",
        "\n",
        "This section integrates our empathy analysis with the Information Systems Research model that examines the relationship between Agent-Empowered Chatbot empathy and user outcomes. The model proposes four hypotheses:\n",
        "\n",
        "- **H1**: Perceived Empathy â†’ Perceived AI Helpfulness\n",
        "- **H2**: Perceived Empathy â†’ User Emotion (Valence & Arousal)  \n",
        "- **H3**: Service Failure Type moderates Empathy â†’ Helpfulness relationship\n",
        "- **H4**: Empathy influences Satisfaction and AI Aversion through multiple pathways\n",
        "\n",
        "### 8.2 Empathy Dimension Mapping\n",
        "\n",
        "Our three empathy dimensions map to the ISR model's empathy constructs:\n",
        "- **Cognitive Empathy (understanding)** â‰ˆ Our **Perspective Taking** dimension\n",
        "- **Affective Empathy (emotional responsiveness)** â‰ˆ Our **Affective Empathy** dimension  \n",
        "- **Associative Empathy (proactive help)** â‰ˆ Our **Concern to Help** dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extended analysis incorporating ISR research model framework\n",
        "if len(df_merged) > 0:\n",
        "    print(\"=== ISR Research Model Analysis ===\")\n",
        "    \n",
        "    # Map our empathy dimensions to ISR model constructs\n",
        "    empathy_mapping = {\n",
        "        'cognitive_empathy': 'perspective_taking',      # Understanding-based empathy\n",
        "        'affective_empathy': 'affective_empathy',       # Emotional responsiveness  \n",
        "        'associative_empathy': 'concern_to_help'        # Proactive help-oriented empathy\n",
        "    }\n",
        "    \n",
        "    print(\"\\\\n1. Empathy Dimension Mapping to ISR Model:\")\n",
        "    for isr_construct, our_dimension in empathy_mapping.items():\n",
        "        mean_score = df_merged[our_dimension].mean()\n",
        "        std_score = df_merged[our_dimension].std()\n",
        "        print(f\"   {isr_construct.replace('_', ' ').title()}: {mean_score:.3f} (Â±{std_score:.3f})\")\n",
        "    \n",
        "    # Analyze perceived helpfulness proxy (using like_binary as satisfaction proxy)\n",
        "    print(\"\\\\n2. H1 Analysis: Empathy â†’ Perceived Helpfulness (Satisfaction)\")\n",
        "    print(\"   Correlation Analysis:\")\n",
        "    \n",
        "    h1_results = {}\n",
        "    for construct, dimension in empathy_mapping.items():\n",
        "        correlation = df_merged[dimension].corr(df_merged['like_binary'])\n",
        "        h1_results[construct] = correlation\n",
        "        print(f\"   {construct.replace('_', ' ').title()} â†’ Satisfaction: r = {correlation:.4f}\")\n",
        "    \n",
        "    # Find strongest empathy predictor\n",
        "    strongest_predictor = max(h1_results, key=h1_results.get)\n",
        "    print(f\"\\\\n   Strongest predictor: {strongest_predictor.replace('_', ' ').title()} (r = {h1_results[strongest_predictor]:.4f})\")\n",
        "    \n",
        "    # Analyze service failure types (using feedback reasons as proxy)\n",
        "    print(\"\\\\n3. H3 Analysis: Service Failure Type Moderation\")\n",
        "    \n",
        "    if 'feedback' in df_merged.columns:\n",
        "        # Categorize service failures based on feedback reasons\n",
        "        failure_categories = {\n",
        "            'factual_error': ['æœ‰äº‹å®žæ€§é”™è¯¯', 'äº‹å®žæ€§é”™è¯¯'],\n",
        "            'unhelpful': ['æ²¡æœ‰å®žé™…å¸®åŠ©', 'æ²¡æœ‰å¸®åŠ©'],\n",
        "            'logic_error': ['é€»è¾‘é”™è¯¯'],\n",
        "            'misunderstanding': ['æ²¡æœ‰ç†è§£é—®é¢˜', 'ç­”éžæ‰€é—®'],\n",
        "            'format_error': ['æ ¼å¼é”™è¯¯']\n",
        "        }\n",
        "        \n",
        "        failure_analysis = []\n",
        "        for category, keywords in failure_categories.items():\n",
        "            # Find records with this type of failure\n",
        "            mask = df_merged['feedback'].str.contains('|'.join(keywords), na=False)\n",
        "            category_data = df_merged[mask]\n",
        "            \n",
        "            if len(category_data) >= 5:  # Need minimum sample size\n",
        "                # Calculate empathy-satisfaction correlation for this failure type\n",
        "                empathy_sat_corr = category_data['total_empathy'].corr(category_data['like_binary'])\n",
        "                \n",
        "                failure_analysis.append({\n",
        "                    'failure_type': category,\n",
        "                    'sample_size': len(category_data),\n",
        "                    'avg_empathy': category_data['total_empathy'].mean(),\n",
        "                    'satisfaction_rate': category_data['like_binary'].mean(),\n",
        "                    'empathy_satisfaction_corr': empathy_sat_corr\n",
        "                })\n",
        "        \n",
        "        if failure_analysis:\n",
        "            failure_df = pd.DataFrame(failure_analysis)\n",
        "            print(\"\\\\n   Service Failure Type Analysis:\")\n",
        "            display(failure_df.round(4))\n",
        "            \n",
        "            # Identify moderation effects\n",
        "            correlations = failure_df['empathy_satisfaction_corr'].dropna()\n",
        "            if len(correlations) > 1:\n",
        "                corr_range = correlations.max() - correlations.min()\n",
        "                print(f\"\\\\n   Moderation Evidence: Correlation range = {corr_range:.4f}\")\n",
        "                if corr_range > 0.2:\n",
        "                    print(\"   â†’ Strong moderation effect detected!\")\n",
        "                else:\n",
        "                    print(\"   â†’ Weak/No moderation effect detected.\")\n",
        "    \n",
        "    print(\"\\\\n4. H2 & H4 Analysis: Empathy â†’ User Emotion â†’ Outcomes\")\n",
        "    \n",
        "    # Create emotion proxy based on feedback characteristics\n",
        "    # Positive emotions: likes, no negative feedback\n",
        "    # Negative emotions: dislikes with specific negative reasons\n",
        "    \n",
        "    df_merged['emotion_valence'] = df_merged['like_binary']  # Simple proxy: like=positive, dislike=negative\n",
        "    \n",
        "    # Create arousal proxy based on feedback intensity (presence of detailed reasons)\n",
        "    df_merged['emotion_arousal'] = df_merged['feedback'].fillna('').str.len() > 10  # Detailed feedback = high arousal\n",
        "    \n",
        "    print(\"   Emotion Analysis (Valence & Arousal proxies):\")\n",
        "    valence_corr = df_merged['total_empathy'].corr(df_merged['emotion_valence'])\n",
        "    arousal_corr = df_merged['total_empathy'].corr(df_merged['emotion_arousal'].astype(int))\n",
        "    \n",
        "    print(f\"   Empathy â†’ Emotion Valence: r = {valence_corr:.4f}\")\n",
        "    print(f\"   Empathy â†’ Emotion Arousal: r = {arousal_corr:.4f}\")\n",
        "    \n",
        "    # Path analysis simulation (simplified structural equation modeling)\n",
        "    print(\"\\\\n5. Path Analysis (Simplified SEM):\")\n",
        "    \n",
        "    # Direct path: Empathy â†’ Satisfaction\n",
        "    direct_path = df_merged['total_empathy'].corr(df_merged['like_binary'])\n",
        "    \n",
        "    # Indirect path: Empathy â†’ Emotion Valence â†’ Satisfaction  \n",
        "    empathy_emotion = df_merged['total_empathy'].corr(df_merged['emotion_valence'])\n",
        "    emotion_satisfaction = df_merged['emotion_valence'].corr(df_merged['like_binary'])\n",
        "    indirect_path = empathy_emotion * emotion_satisfaction\n",
        "    \n",
        "    total_effect = direct_path + indirect_path\n",
        "    mediation_ratio = indirect_path / total_effect if total_effect != 0 else 0\n",
        "    \n",
        "    print(f\"   Direct Effect (Empathy â†’ Satisfaction): {direct_path:.4f}\")\n",
        "    print(f\"   Indirect Effect (Empathy â†’ Emotion â†’ Satisfaction): {indirect_path:.4f}\")\n",
        "    print(f\"   Total Effect: {total_effect:.4f}\")\n",
        "    print(f\"   Mediation Ratio: {mediation_ratio:.1%}\")\n",
        "    \n",
        "else:\n",
        "    print(\"No merged data available for ISR model analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ISR Model Visualization\n",
        "if len(df_merged) > 0:\n",
        "    print(\"\\\\n=== ISR Model Visualization ===\")\n",
        "    \n",
        "    # Create comprehensive ISR model visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    fig.suptitle('ISR Research Model Analysis - Empathy Pathways', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Three empathy dimensions correlation with satisfaction (H1)\n",
        "    ax1 = axes[0, 0]\n",
        "    empathy_dims = ['perspective_taking', 'concern_to_help', 'affective_empathy']\n",
        "    dim_labels = ['Cognitive\\\\n(Perspective)', 'Associative\\\\n(Help)', 'Affective\\\\n(Emotion)']\n",
        "    correlations = [df_merged[dim].corr(df_merged['like_binary']) for dim in empathy_dims]\n",
        "    \n",
        "    colors = ['lightblue' if x > 0 else 'lightcoral' for x in correlations]\n",
        "    bars = ax1.bar(dim_labels, correlations, color=colors, alpha=0.8)\n",
        "    ax1.set_ylabel('Correlation with Satisfaction')\n",
        "    ax1.set_title('H1: Empathy Dimensions â†’ Satisfaction')\n",
        "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add correlation values on bars\n",
        "    for bar, corr in zip(bars, correlations):\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01 if height > 0 else height - 0.02,\n",
        "                f'{corr:.3f}', ha='center', va='bottom' if height > 0 else 'top')\n",
        "    \n",
        "    # 2. Service failure type moderation (H3)\n",
        "    ax2 = axes[0, 1]\n",
        "    if 'failure_df' in locals() and len(failure_df) > 0:\n",
        "        failure_types = failure_df['failure_type'].tolist()\n",
        "        empathy_corrs = failure_df['empathy_satisfaction_corr'].tolist()\n",
        "        \n",
        "        ax2.bar(range(len(failure_types)), empathy_corrs, \n",
        "                color=['red' if x < 0 else 'green' for x in empathy_corrs], alpha=0.7)\n",
        "        ax2.set_xticks(range(len(failure_types)))\n",
        "        ax2.set_xticklabels([ft.replace('_', '\\\\n') for ft in failure_types], rotation=45)\n",
        "        ax2.set_ylabel('Empathy-Satisfaction Correlation')\n",
        "        ax2.set_title('H3: Moderation by Failure Type')\n",
        "        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax2.text(0.5, 0.5, 'Insufficient failure\\\\ntype data', ha='center', va='center', transform=ax2.transAxes)\n",
        "        ax2.set_title('H3: Moderation by Failure Type')\n",
        "    \n",
        "    # 3. Empathy-Emotion pathway (H2)\n",
        "    ax3 = axes[0, 2]\n",
        "    if 'emotion_valence' in df_merged.columns:\n",
        "        # Scatter plot with trend line\n",
        "        ax3.scatter(df_merged['total_empathy'], df_merged['emotion_valence'], alpha=0.6, s=30)\n",
        "        \n",
        "        # Add trend line\n",
        "        z = np.polyfit(df_merged['total_empathy'], df_merged['emotion_valence'], 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax3.plot(df_merged['total_empathy'].sort_values(), p(df_merged['total_empathy'].sort_values()), \n",
        "                \"r--\", alpha=0.8, linewidth=2)\n",
        "        \n",
        "        ax3.set_xlabel('Total Empathy Score')\n",
        "        ax3.set_ylabel('Emotion Valence (0=Negative, 1=Positive)')\n",
        "        ax3.set_title(f'H2: Empathy â†’ Emotion\\\\n(r = {valence_corr:.3f})')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Path analysis visualization (H4)\n",
        "    ax4 = axes[1, 0]\n",
        "    if 'direct_path' in locals():\n",
        "        # Create path diagram representation\n",
        "        paths = ['Direct\\\\nPath', 'Indirect\\\\nPath', 'Total\\\\nEffect']\n",
        "        path_strengths = [abs(direct_path), abs(indirect_path), abs(total_effect)]\n",
        "        path_colors = ['blue', 'orange', 'green']\n",
        "        \n",
        "        bars = ax4.bar(paths, path_strengths, color=path_colors, alpha=0.7)\n",
        "        ax4.set_ylabel('Effect Strength (|correlation|)')\n",
        "        ax4.set_title('H4: Path Analysis Effects')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add values on bars\n",
        "        for bar, strength in zip(bars, [direct_path, indirect_path, total_effect]):\n",
        "            height = bar.get_height()\n",
        "            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                    f'{strength:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    # 5. Empathy dimension interaction effects\n",
        "    ax5 = axes[1, 1]\n",
        "    # Create interaction heatmap\n",
        "    empathy_corr_matrix = df_merged[empathy_dims + ['like_binary']].corr()\n",
        "    im = ax5.imshow(empathy_corr_matrix, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
        "    \n",
        "    ax5.set_xticks(range(len(empathy_dims) + 1))\n",
        "    ax5.set_yticks(range(len(empathy_dims) + 1))\n",
        "    ax5.set_xticklabels(['Cognitive', 'Associative', 'Affective', 'Satisfaction'], rotation=45)\n",
        "    ax5.set_yticklabels(['Cognitive', 'Associative', 'Affective', 'Satisfaction'])\n",
        "    ax5.set_title('Empathy Dimensions Correlation Matrix')\n",
        "    \n",
        "    # Add correlation values\n",
        "    for i in range(len(empathy_dims) + 1):\n",
        "        for j in range(len(empathy_dims) + 1):\n",
        "            ax5.text(j, i, f'{empathy_corr_matrix.iloc[i, j]:.2f}', \n",
        "                    ha='center', va='center', fontsize=9)\n",
        "    \n",
        "    plt.colorbar(im, ax=ax5, shrink=0.8)\n",
        "    \n",
        "    # 6. Mediation analysis\n",
        "    ax6 = axes[1, 2]\n",
        "    if 'mediation_ratio' in locals():\n",
        "        # Pie chart of direct vs indirect effects\n",
        "        sizes = [abs(direct_path), abs(indirect_path)]\n",
        "        labels = ['Direct Effect', 'Indirect Effect']\n",
        "        colors = ['lightblue', 'lightyellow']\n",
        "        \n",
        "        if sum(sizes) > 0:\n",
        "            ax6.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "            ax6.set_title(f'Effect Decomposition\\\\nMediation: {mediation_ratio:.1%}')\n",
        "        else:\n",
        "            ax6.text(0.5, 0.5, 'No significant\\\\neffects detected', ha='center', va='center', transform=ax6.transAxes)\n",
        "            ax6.set_title('Effect Decomposition')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot create ISR model visualizations due to no merged data.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 9. Updated Analysis Report with ISR Model Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Updated comprehensive analysis report with ISR model integration\n",
        "if len(df_merged) > 0:\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"         ENHANCED EMPATHY ANALYSIS REPORT\")\n",
        "    print(\"    ISR Research Model Integration - Beihai AI Companion\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Executive Summary\n",
        "    print(\"\\\\nðŸ” EXECUTIVE SUMMARY\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"â€¢ Dataset Size: {len(df_merged):,} analyzed conversations with feedback\")\n",
        "    print(f\"â€¢ Analysis Framework: ISR Research Model + Three-Dimensional Empathy Analysis\")\n",
        "    print(f\"â€¢ Overall Satisfaction Rate: {df_merged['like_binary'].mean():.1%}\")\n",
        "    print(f\"â€¢ Average Total Empathy Score: {df_merged['total_empathy'].mean():.2f}\")\n",
        "    \n",
        "    # ISR Model Hypothesis Testing Results\n",
        "    print(\"\\\\nðŸ“Š ISR MODEL HYPOTHESIS TESTING\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    if 'h1_results' in locals():\n",
        "        print(\"\\\\n1. H1: Perceived Empathy â†’ Perceived AI Helpfulness\")\n",
        "        for construct, correlation in h1_results.items():\n",
        "            support = \"âœ… SUPPORTED\" if correlation > 0.1 else \"âŒ NOT SUPPORTED\" if correlation < -0.1 else \"âš ï¸ WEAK SUPPORT\"\n",
        "            print(f\"   â€¢ {construct.replace('_', ' ').title()}: r = {correlation:.4f} - {support}\")\n",
        "        \n",
        "        strongest = max(h1_results, key=h1_results.get)\n",
        "        print(f\"   â€¢ Strongest empathy predictor: {strongest.replace('_', ' ').title()}\")\n",
        "    \n",
        "    if 'valence_corr' in locals():\n",
        "        print(\"\\\\n2. H2: Perceived Empathy â†’ User Emotion\")\n",
        "        valence_support = \"âœ… SUPPORTED\" if valence_corr > 0.1 else \"âŒ NOT SUPPORTED\" if valence_corr < -0.1 else \"âš ï¸ WEAK SUPPORT\"\n",
        "        arousal_support = \"âœ… SUPPORTED\" if abs(arousal_corr) > 0.1 else \"âš ï¸ WEAK SUPPORT\"\n",
        "        print(f\"   â€¢ Empathy â†’ Emotion Valence: r = {valence_corr:.4f} - {valence_support}\")\n",
        "        print(f\"   â€¢ Empathy â†’ Emotion Arousal: r = {arousal_corr:.4f} - {arousal_support}\")\n",
        "    \n",
        "    if 'failure_df' in locals() and len(failure_df) > 0:\n",
        "        print(\"\\\\n3. H3: Service Failure Type Moderation\")\n",
        "        correlations = failure_df['empathy_satisfaction_corr'].dropna()\n",
        "        if len(correlations) > 1:\n",
        "            corr_range = correlations.max() - correlations.min()\n",
        "            moderation_support = \"âœ… SUPPORTED\" if corr_range > 0.2 else \"âš ï¸ WEAK SUPPORT\"\n",
        "            print(f\"   â€¢ Moderation Effect Range: {corr_range:.4f} - {moderation_support}\")\n",
        "            print(f\"   â€¢ Different failure types show varying empathy effectiveness\")\n",
        "        else:\n",
        "            print(\"   â€¢ Insufficient data for moderation analysis\")\n",
        "    \n",
        "    if 'mediation_ratio' in locals():\n",
        "        print(\"\\\\n4. H4: Multiple Pathways (Direct + Indirect Effects)\")\n",
        "        pathway_support = \"âœ… SUPPORTED\" if mediation_ratio > 0.1 else \"âš ï¸ WEAK SUPPORT\"\n",
        "        print(f\"   â€¢ Direct Effect: {direct_path:.4f}\")\n",
        "        print(f\"   â€¢ Indirect Effect (via Emotion): {indirect_path:.4f}\")\n",
        "        print(f\"   â€¢ Mediation Ratio: {mediation_ratio:.1%} - {pathway_support}\")\n",
        "    \n",
        "    # Enhanced Strategic Recommendations\n",
        "    print(\"\\\\nðŸ’¡ STRATEGIC RECOMMENDATIONS (ISR Model-Based)\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    print(\"\\\\n1. ðŸŽ¯ EMPATHY DIMENSION PRIORITIZATION:\")\n",
        "    if 'h1_results' in locals():\n",
        "        # Rank empathy dimensions by effectiveness\n",
        "        sorted_empathy = sorted(h1_results.items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (construct, corr) in enumerate(sorted_empathy, 1):\n",
        "            priority = \"HIGH\" if i == 1 else \"MEDIUM\" if i == 2 else \"LOW\"\n",
        "            print(f\"   {i}. {construct.replace('_', ' ').title()} (r={corr:.3f}) - {priority} Priority\")\n",
        "    \n",
        "    print(\"\\\\n2. ðŸ“ FAILURE-TYPE SPECIFIC STRATEGIES:\")\n",
        "    if 'failure_df' in locals() and len(failure_df) > 0:\n",
        "        for _, row in failure_df.iterrows():\n",
        "            effectiveness = \"High\" if row['empathy_satisfaction_corr'] > 0.2 else \"Low\" if row['empathy_satisfaction_corr'] < 0 else \"Medium\"\n",
        "            print(f\"   â€¢ {row['failure_type'].replace('_', ' ').title()}: {effectiveness} empathy effectiveness\")\n",
        "            if effectiveness == \"Low\":\n",
        "                print(f\"     â†’ Focus on technical fixes rather than empathy for this failure type\")\n",
        "            else:\n",
        "                print(f\"     â†’ Empathy interventions recommended for this failure type\")\n",
        "    \n",
        "    print(\"\\\\n3. ðŸ§  EMOTION-MEDIATED PATHWAY OPTIMIZATION:\")\n",
        "    if 'mediation_ratio' in locals():\n",
        "        if mediation_ratio > 0.2:\n",
        "            print(\"   â€¢ Strong emotional mediation detected - focus on emotional language\")\n",
        "            print(\"   â€¢ Train AI to recognize and respond to user emotional states\")\n",
        "            print(\"   â€¢ Implement emotion-aware response generation\")\n",
        "        else:\n",
        "            print(\"   â€¢ Weak emotional mediation - focus on direct helpfulness\")\n",
        "            print(\"   â€¢ Prioritize factual accuracy over emotional responsiveness\")\n",
        "    \n",
        "    print(\"\\\\n4. ðŸ”§ TECHNICAL IMPLEMENTATION:\")\n",
        "    print(\"   â€¢ Implement multi-dimensional empathy scoring (cognitive, affective, associative)\")\n",
        "    print(\"   â€¢ Develop context-aware empathy calibration based on failure types\")\n",
        "    print(\"   â€¢ Create emotion detection and response adaptation systems\")\n",
        "    print(\"   â€¢ Establish empathy-outcome monitoring dashboards\")\n",
        "    \n",
        "    print(\"\\\\n5. ðŸ“ˆ MEASUREMENT & EVALUATION:\")\n",
        "    print(\"   â€¢ Track empathy dimension scores separately\")\n",
        "    print(\"   â€¢ Monitor failure-type specific empathy effectiveness\")\n",
        "    print(\"   â€¢ Measure emotional valence and arousal in user responses\")\n",
        "    print(\"   â€¢ Conduct regular path analysis to validate theoretical model\")\n",
        "    \n",
        "    # ISR Model Theoretical Contributions\n",
        "    print(\"\\\\nðŸŽ“ THEORETICAL CONTRIBUTIONS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"\\\\nâ€¢ Empirical validation of ISR empathy model in Chinese travel domain\")\n",
        "    print(\"â€¢ Evidence for multi-dimensional empathy effects on user satisfaction\")\n",
        "    print(\"â€¢ Demonstration of context-dependent empathy effectiveness\")\n",
        "    print(\"â€¢ Support for emotion-mediated pathways in AI-human interaction\")\n",
        "    \n",
        "    # Enhanced Future Research\n",
        "    print(\"\\\\nðŸ”¬ ENHANCED FUTURE RESEARCH DIRECTIONS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"â€¢ Structural Equation Modeling (SEM) for rigorous path analysis\")\n",
        "    print(\"â€¢ Longitudinal analysis of empathy adaptation over time\")\n",
        "    print(\"â€¢ Cross-cultural validation of empathy dimensions\")\n",
        "    print(\"â€¢ Integration with advanced emotion detection technologies\")\n",
        "    print(\"â€¢ Development of empathy-outcome causal inference models\")\n",
        "    \n",
        "    # Model Limitations\n",
        "    print(\"\\\\nâš ï¸ ISR MODEL ANALYSIS LIMITATIONS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"â€¢ Proxy measures used for theoretical constructs (emotion, helpfulness)\")\n",
        "    print(\"â€¢ Cross-sectional data limits causal inference\")\n",
        "    print(\"â€¢ Keyword-based empathy detection may miss contextual nuances\")\n",
        "    print(\"â€¢ Sample size constraints for robust SEM analysis\")\n",
        "    print(\"â€¢ Single domain (travel) limits generalizability\")\n",
        "    \n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"ISR Model Integration enhances understanding of empathy mechanisms\")\n",
        "    print(\"Provides actionable insights for AI system improvement\")\n",
        "    print(f\"Report generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "else:\n",
        "    print(\"\\\\nâš ï¸ ISR MODEL ANALYSIS INCOMPLETE\")\n",
        "    print(\"No merged data available for comprehensive ISR model analysis.\")\n",
        "    print(\"Please check data loading and merging procedures.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ISR Model Path Diagram\n",
        "if len(df_merged) > 0:\n",
        "    print(\"\\\\n=== ISR Model Path Diagram ===\")\n",
        "    \n",
        "    # Create a conceptual path diagram representation\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(14, 10))\n",
        "    \n",
        "    # Define node positions for the path diagram\n",
        "    positions = {\n",
        "        'empathy': (2, 6),\n",
        "        'helpfulness': (6, 8),\n",
        "        'emotion': (6, 4),\n",
        "        'satisfaction': (10, 6),\n",
        "        'failure_type': (2, 9)\n",
        "    }\n",
        "    \n",
        "    # Create boxes for each construct\n",
        "    box_props = dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7, edgecolor=\"black\")\n",
        "    \n",
        "    # Draw construct boxes\n",
        "    ax.text(positions['empathy'][0], positions['empathy'][1], \n",
        "            'Perceived Empathy\\\\n(3 Dimensions)', ha='center', va='center', \n",
        "            bbox=box_props, fontsize=10, fontweight='bold')\n",
        "    \n",
        "    ax.text(positions['helpfulness'][0], positions['helpfulness'][1], \n",
        "            'Perceived AI\\\\nHelpfulness', ha='center', va='center', \n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7, edgecolor=\"black\"), \n",
        "            fontsize=10, fontweight='bold')\n",
        "    \n",
        "    ax.text(positions['emotion'][0], positions['emotion'][1], \n",
        "            'User Emotion\\\\n(Valence & Arousal)', ha='center', va='center', \n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\", alpha=0.7, edgecolor=\"black\"), \n",
        "            fontsize=10, fontweight='bold')\n",
        "    \n",
        "    ax.text(positions['satisfaction'][0], positions['satisfaction'][1], \n",
        "            'Satisfaction\\\\n& AI Aversion', ha='center', va='center', \n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightcoral\", alpha=0.7, edgecolor=\"black\"), \n",
        "            fontsize=10, fontweight='bold')\n",
        "    \n",
        "    ax.text(positions['failure_type'][0], positions['failure_type'][1], \n",
        "            'Service Failure\\\\nType', ha='center', va='center', \n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.7, edgecolor=\"black\"), \n",
        "            fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # Draw paths with correlation strength\n",
        "    if 'h1_results' in locals():\n",
        "        # H1: Empathy â†’ Helpfulness\n",
        "        avg_empathy_help_corr = np.mean(list(h1_results.values()))\n",
        "        arrow_props = dict(arrowstyle='->', lw=2, color='blue', alpha=0.8)\n",
        "        ax.annotate('', xy=(positions['helpfulness'][0]-0.5, positions['helpfulness'][1]), \n",
        "                   xytext=(positions['empathy'][0]+0.5, positions['empathy'][1]+0.5),\n",
        "                   arrowprops=arrow_props)\n",
        "        ax.text(4, 7.5, f'H1\\\\nr={avg_empathy_help_corr:.3f}', ha='center', va='center', \n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.8), fontsize=9)\n",
        "    \n",
        "    if 'valence_corr' in locals():\n",
        "        # H2: Empathy â†’ Emotion\n",
        "        arrow_props = dict(arrowstyle='->', lw=2, color='orange', alpha=0.8)\n",
        "        ax.annotate('', xy=(positions['emotion'][0]-0.5, positions['emotion'][1]), \n",
        "                   xytext=(positions['empathy'][0]+0.5, positions['empathy'][1]-0.5),\n",
        "                   arrowprops=arrow_props)\n",
        "        ax.text(4, 4.5, f'H2\\\\nr={valence_corr:.3f}', ha='center', va='center', \n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.8), fontsize=9)\n",
        "    \n",
        "    # H3: Moderation effect\n",
        "    if 'failure_df' in locals() and len(failure_df) > 0:\n",
        "        # Draw moderation arrow\n",
        "        arrow_props = dict(arrowstyle='->', lw=1.5, color='purple', alpha=0.8, linestyle='dashed')\n",
        "        ax.annotate('', xy=(4, 7.5), xytext=(positions['failure_type'][0], positions['failure_type'][1]-0.5),\n",
        "                   arrowprops=arrow_props)\n",
        "        ax.text(2.5, 8, 'H3\\\\n(Moderates)', ha='center', va='center', \n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.8), fontsize=8)\n",
        "    \n",
        "    # Paths to satisfaction\n",
        "    if 'direct_path' in locals():\n",
        "        # Direct path: Empathy â†’ Satisfaction\n",
        "        arrow_props = dict(arrowstyle='->', lw=3, color='green', alpha=0.8)\n",
        "        ax.annotate('', xy=(positions['satisfaction'][0]-1, positions['satisfaction'][1]), \n",
        "                   xytext=(positions['empathy'][0]+1, positions['empathy'][1]),\n",
        "                   arrowprops=arrow_props)\n",
        "        ax.text(6, 6.5, f'Direct\\\\nr={direct_path:.3f}', ha='center', va='center', \n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.8), fontsize=9)\n",
        "        \n",
        "        # Helpfulness â†’ Satisfaction\n",
        "        arrow_props = dict(arrowstyle='->', lw=2, color='darkgreen', alpha=0.8)\n",
        "        ax.annotate('', xy=(positions['satisfaction'][0]-0.5, positions['satisfaction'][1]+0.5), \n",
        "                   xytext=(positions['helpfulness'][0]+0.5, positions['helpfulness'][1]-0.5),\n",
        "                   arrowprops=arrow_props)\n",
        "        \n",
        "        # Emotion â†’ Satisfaction\n",
        "        arrow_props = dict(arrowstyle='->', lw=2, color='darkgreen', alpha=0.8)\n",
        "        ax.annotate('', xy=(positions['satisfaction'][0]-0.5, positions['satisfaction'][1]-0.5), \n",
        "                   xytext=(positions['emotion'][0]+0.5, positions['emotion'][1]+0.5),\n",
        "                   arrowprops=arrow_props)\n",
        "        \n",
        "        ax.text(8.5, 5, f'H4: Indirect\\\\nr={indirect_path:.3f}', ha='center', va='center', \n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.8), fontsize=9)\n",
        "    \n",
        "    # Add empathy dimensions\n",
        "    dim_y_positions = [5.5, 6, 6.5]\n",
        "    dim_labels = ['Cognitive\\\\n(Perspective)', 'Affective\\\\n(Emotion)', 'Associative\\\\n(Help)']\n",
        "    dim_correlations = [df_merged['perspective_taking'].corr(df_merged['like_binary']),\n",
        "                       df_merged['affective_empathy'].corr(df_merged['like_binary']),\n",
        "                       df_merged['concern_to_help'].corr(df_merged['like_binary'])]\n",
        "    \n",
        "    for i, (label, corr, y_pos) in enumerate(zip(dim_labels, dim_correlations, dim_y_positions)):\n",
        "        ax.text(0.5, y_pos, label, ha='center', va='center', \n",
        "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"lightsteelblue\", alpha=0.6), \n",
        "                fontsize=8)\n",
        "        \n",
        "        # Draw connection to main empathy construct\n",
        "        ax.plot([1, 1.5], [y_pos, 6], 'k-', alpha=0.5, lw=1)\n",
        "        ax.text(1.2, y_pos-0.2, f'r={corr:.2f}', ha='center', va='center', fontsize=7)\n",
        "    \n",
        "    # Add title and formatting\n",
        "    ax.set_xlim(-0.5, 12)\n",
        "    ax.set_ylim(3, 10)\n",
        "    ax.set_title('ISR Research Model - Empathy Pathways in AI Companion Interaction', \n",
        "                fontsize=14, fontweight='bold', pad=20)\n",
        "    \n",
        "    # Remove axes\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    \n",
        "    # Add legend\n",
        "    legend_elements = [\n",
        "        plt.Line2D([0], [0], color='blue', lw=2, label='H1: Empathy â†’ Helpfulness'),\n",
        "        plt.Line2D([0], [0], color='orange', lw=2, label='H2: Empathy â†’ Emotion'),\n",
        "        plt.Line2D([0], [0], color='purple', lw=1.5, linestyle='dashed', label='H3: Failure Type Moderation'),\n",
        "        plt.Line2D([0], [0], color='green', lw=2, label='H4: Direct & Indirect Effects')\n",
        "    ]\n",
        "    ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1, 1))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot create ISR model path diagram due to no merged data.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data-analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
